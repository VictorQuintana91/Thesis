{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import plotly \n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "print(cf.__version__)\n",
    "# Configure cufflings \n",
    "cf.set_config_file(offline=False, world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "# !pip install autocorrect\n",
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For monitoring duration of pandas processes\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# To avoid RuntimeError: Set changed size during iteration\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# can also groupby:\n",
    "# df.groupby(0).progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getDF('/Users/falehalrashidi/Downloads/reviews_Books_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Adam</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wonderful!</td>\n",
       "      <td>1355616000</td>\n",
       "      <td>12 16, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>adead_poet@hotmail.com \"adead_poet@hotmail.com\"</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>close to god</td>\n",
       "      <td>1071100800</td>\n",
       "      <td>12 11, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Ahoro Blethends \"Seriously\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Must Read for Life Afficianados</td>\n",
       "      <td>1390003200</td>\n",
       "      <td>01 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alan Krug</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Timeless for every good and bad time in your l...</td>\n",
       "      <td>1317081600</td>\n",
       "      <td>09 27, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alaturka</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A Modern Rumi</td>\n",
       "      <td>1033948800</td>\n",
       "      <td>10 7, 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                      reviewerName helpful  \\\n",
       "0                                             Adam  [0, 0]   \n",
       "1  adead_poet@hotmail.com \"adead_poet@hotmail.com\"  [0, 2]   \n",
       "2                      Ahoro Blethends \"Seriously\"  [0, 0]   \n",
       "3                                        Alan Krug  [0, 0]   \n",
       "4                                         Alaturka  [7, 9]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...      5.0   \n",
       "1  This is one my must have books. It is a master...      5.0   \n",
       "2  This book provides a reflection that you can a...      5.0   \n",
       "3  I first read THE PROPHET in college back in th...      5.0   \n",
       "4  A timeless classic.  It is a very demanding an...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                         Wonderful!      1355616000   \n",
       "1                                       close to god      1071100800   \n",
       "2                    Must Read for Life Afficianados      1390003200   \n",
       "3  Timeless for every good and bad time in your l...      1317081600   \n",
       "4                                      A Modern Rumi      1033948800   \n",
       "\n",
       "    reviewTime  \n",
       "0  12 16, 2012  \n",
       "1  12 11, 2003  \n",
       "2  01 18, 2014  \n",
       "3  09 27, 2011  \n",
       "4   10 7, 2002  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1 = df[['reviewerID','asin','reviewText','helpful']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  \n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]  \n",
       "1  This is one my must have books. It is a master...  [0, 2]  \n",
       "2  This book provides a reflection that you can a...  [0, 0]  \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]  \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8898041"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 8898041/8898041 [00:06<00:00, 1405510.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create new Column for the denominator\n",
    "df2 = df1.assign(denom = df1['helpful'].progress_apply(lambda enum_denom:enum_denom[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>denom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  denom  \n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]      0  \n",
       "1  This is one my must have books. It is a master...  [0, 2]      2  \n",
       "2  This book provides a reflection that you can a...  [0, 0]      0  \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]      0  \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]      9  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Uniquekey Column\n",
    "df3 = df2.assign(uniqueKey = df['reviewerID'].str.cat(df['asin'].values.astype(str), sep='##'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>denom</th>\n",
       "      <th>uniqueKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>9</td>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  denom  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]      0   \n",
       "1  This is one my must have books. It is a master...  [0, 2]      2   \n",
       "2  This book provides a reflection that you can a...  [0, 0]      0   \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]      0   \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]      9   \n",
       "\n",
       "                           uniqueKey  \n",
       "0  A10000012B7CGYKOMPQ4L##000100039X  \n",
       "1         A2S166WSCFIFP5##000100039X  \n",
       "2         A1BM81XB4QHOA3##000100039X  \n",
       "3         A1MOSTXNIO5MPJ##000100039X  \n",
       "4         A2XQ5LZHTD4AFT##000100039X  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey  \\\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X   \n",
       "1         A2S166WSCFIFP5##000100039X   \n",
       "2         A1BM81XB4QHOA3##000100039X   \n",
       "3         A1MOSTXNIO5MPJ##000100039X   \n",
       "4         A2XQ5LZHTD4AFT##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  Spiritually and mentally inspiring! A book tha...  \n",
       "1  This is one my must have books. It is a master...  \n",
       "2  This book provides a reflection that you can a...  \n",
       "3  I first read THE PROPHET in college back in th...  \n",
       "4  A timeless classic.  It is a very demanding an...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns necessary for the normalisation\n",
    "df4 = df3[['uniqueKey', 'reviewText']]\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was necessary due to weird keyErrors that followed after trying to process the reviewText as a `pandas.DataFrame` and not as `pandas.Series`. After experimenting with both, I found that `pandas.Series.apply` is faster than `pandas.DataFrame.apply` and so I will hence work with `pandas.Series`. \n",
    "\n",
    "The assumption I require to make at this point before I follow is that `pandas` will not change the index of the reviews as those are being processed by my code and that in the end of my processing I will be able to re-associate those reviews with their **uniqueKey**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X\n",
       "1         A2S166WSCFIFP5##000100039X\n",
       "2         A1BM81XB4QHOA3##000100039X\n",
       "3         A1MOSTXNIO5MPJ##000100039X\n",
       "4         A2XQ5LZHTD4AFT##000100039X"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueKey_series_df = df4[['uniqueKey']]\n",
    "uniqueKey_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 8898041/8898041 [00:09<00:00, 985818.68it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  Spiritually and mentally inspiring! A book tha...\n",
       "1  This is one my must have books. It is a master...\n",
       "2  This book provides a reflection that you can a...\n",
       "3  I first read THE PROPHET in college back in th...\n",
       "4  A timeless classic.  It is a very demanding an..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame(df4['reviewText'].progress_apply(lambda review: review.split(\"\\n\")[0]))\n",
    "reviews_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation\n",
    "<span style=\"color:red\">**NOTICE:** As I am in a hurry to complete the first pipeline, I will only work with the first 100k reviews.</span>\n",
    "\n",
    "* Tokenization <span style=\"color:blue\"> DONE </span>\n",
    "* Convert All Tokens to Lowercase <span style=\"color:blue\"> DONE </span>\n",
    "* Eliminate Punctuation <span style=\"color:blue\"> DONE </span>\n",
    "* Remove Stop Words <span style=\"color:blue\"> DONE </span>\n",
    "* Changing Numbers into Words <span style=\"color:blue\"> DONE </span>\n",
    "* Expand Abbreviations <span style=\"color:red\"> NOT AS EASY AS I THOUGHT AND DOES NOT ADD MUCH VALUE (Ask Stasha's opinion)</span> \n",
    "* Correct Spelling <span style=\"color:red\"> TOO SLOW (10h for 100k reviews)-->SO WONT DO</span>\n",
    "* Substituting Tokens with Synonyms <span style=\"color:green\"> TO DO</span>\n",
    "* Semantical Marking of Negatives <span style=\"color:blue\"> DONE (Ask Stasha's opinion) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [01:18<00:00, 1274.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [Spiritually, and, mentally, inspiring, !, A, ...\n",
       "1    [This, is, one, my, must, have, books, ., It, ...\n",
       "2    [This, book, provides, a, reflection, that, yo...\n",
       "3    [I, first, read, THE, PROPHET, in, college, ba...\n",
       "4    [A, timeless, classic, ., It, is, a, very, dem...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_0_df = reviews_df['reviewText'][0:99999].progress_apply(lambda review: nltk.word_tokenize(review))\n",
    "step_0_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Tokens to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def convert_to_lowercase(review):\n",
    "\n",
    "    for i in range(len(review)):\n",
    "        review[i] = review[i].lower()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 51196.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, !, a, ...\n",
       "1    [this, is, one, my, must, have, books, ., it, ...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, ., it, is, a, very, dem...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_1_df = step_0_df.progress_apply(lambda review: convert_to_lowercase(review))\n",
    "step_1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def eliminate_punctuation(review, regex):\n",
    "    new_review = []\n",
    "    for token in review:\n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            new_review.append(new_token)\n",
    "    return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:05<00:00, 17621.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, a, boo...\n",
       "1    [this, is, one, my, must, have, books, it, is,...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, it, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex=re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "step_2_df = step_1_df.progress_apply(lambda review: eliminate_punctuation(review, regex))\n",
    "step_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress::   0%|          | 0/99999 [00:00<?, ?it/s]\u001b[A\n",
      "Progress::   8%|▊         | 8147/99999 [00:00<00:01, 81468.33it/s]\u001b[A\n",
      "Progress::  16%|█▌        | 15553/99999 [00:00<00:01, 79093.80it/s]\u001b[A\n",
      "Progress::  23%|██▎       | 23455/99999 [00:00<00:00, 79071.16it/s]\u001b[A\n",
      "Progress::  33%|███▎      | 33062/99999 [00:00<00:00, 83502.64it/s]\u001b[A\n",
      "Progress::  44%|████▎     | 43562/99999 [00:00<00:00, 88967.06it/s]\u001b[A\n",
      "Progress::  51%|█████▏    | 51313/99999 [00:00<00:00, 85187.76it/s]\u001b[A\n",
      "Progress::  59%|█████▉    | 59013/99999 [00:00<00:00, 80181.36it/s]\u001b[A\n",
      "Progress::  67%|██████▋   | 66611/99999 [00:00<00:00, 78865.55it/s]\u001b[A\n",
      "Progress::  74%|███████▍  | 74144/99999 [00:00<00:00, 76100.16it/s]\u001b[A\n",
      "Progress::  83%|████████▎ | 82817/99999 [00:01<00:00, 79004.64it/s]\u001b[A\n",
      "Progress::  91%|█████████ | 90587/99999 [00:01<00:00, 77353.79it/s]\u001b[A\n",
      "Progress::  98%|█████████▊| 98239/99999 [00:01<00:00, 76796.10it/s]\u001b[A\n",
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 80127.21it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, mentally, inspiring, book, allow...\n",
       "1    [one, must, books, masterpiece, spirituality, ...\n",
       "2    [book, provides, reflection, apply, lifeand, w...\n",
       "3    [first, read, prophet, college, back, 60, book...\n",
       "4    [timeless, classic, demanding, assuming, title...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Remove Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    return [token for token in review if not token in stop_words]\n",
    "\n",
    "step_3_df = step_2_df.progress_apply(lambda review: remove_stopwords(review))\n",
    "step_3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Changing Numbers into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def numStringToWord(review, p):\n",
    "\n",
    "    for i in range(len(review)):\n",
    "        if(review[i].isdigit()):\n",
    "            review[i] = p.number_to_words(review[i])\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress::   0%|          | 0/99999 [00:00<?, ?it/s]\u001b[A\n",
      "Progress::   6%|▌         | 5623/99999 [00:00<00:01, 56228.85it/s]\u001b[A\n",
      "Progress::  11%|█         | 11007/99999 [00:00<00:01, 55488.85it/s]\u001b[A\n",
      "Progress::  16%|█▌        | 15943/99999 [00:00<00:01, 53495.60it/s]\u001b[A\n",
      "Progress::  21%|██▏       | 21294/99999 [00:00<00:01, 53497.37it/s]\u001b[A\n",
      "Progress::  27%|██▋       | 27253/99999 [00:00<00:01, 55190.19it/s]\u001b[A\n",
      "Progress::  34%|███▎      | 33695/99999 [00:00<00:01, 57666.60it/s]\u001b[A\n",
      "Progress::  40%|███▉      | 39520/99999 [00:00<00:01, 57839.75it/s]\u001b[A\n",
      "Progress::  45%|████▍     | 44872/99999 [00:00<00:01, 50725.04it/s]\u001b[A\n",
      "Progress::  50%|████▉     | 49801/99999 [00:00<00:01, 50064.28it/s]\u001b[A\n",
      "Progress::  55%|█████▍    | 54709/99999 [00:01<00:00, 47386.23it/s]\u001b[A\n",
      "Progress::  60%|█████▉    | 59761/99999 [00:01<00:00, 48276.33it/s]\u001b[A\n",
      "Progress::  65%|██████▍   | 64566/99999 [00:01<00:00, 47776.47it/s]\u001b[A\n",
      "Progress::  69%|██████▉   | 69329/99999 [00:01<00:00, 46729.23it/s]\u001b[A\n",
      "Progress::  74%|███████▍  | 73997/99999 [00:01<00:00, 44624.26it/s]\u001b[A\n",
      "Progress::  80%|███████▉  | 79613/99999 [00:01<00:00, 47553.10it/s]\u001b[A\n",
      "Progress::  86%|████████▌ | 85665/99999 [00:01<00:00, 50793.31it/s]\u001b[A\n",
      "Progress::  91%|█████████ | 90851/99999 [00:01<00:00, 47988.19it/s]\u001b[A\n",
      "Progress::  96%|█████████▌| 95849/99999 [00:01<00:00, 48548.19it/s]\u001b[A\n",
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 50292.91it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, mentally, inspiring, book, allow...\n",
       "1    [one, must, books, masterpiece, spirituality, ...\n",
       "2    [book, provides, reflection, apply, lifeand, w...\n",
       "3    [first, read, prophet, college, back, sixty, b...\n",
       "4    [timeless, classic, demanding, assuming, title...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_4_df = step_3_df.progress_apply(lambda review: numStringToWord(review, p))\n",
    "step_4_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Spelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from autocorrect import spell\n",
    "\n",
    "# def spellCheck(review):\n",
    "\n",
    "#     for i in range(len(review)):\n",
    "#         review[i] = spell(review[i])\n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_5_df = step_4_df.progress_apply(lambda review: spellCheck(review))\n",
    "# step_5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting Tokens with Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantical Marking of Negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def negation_tokenizer(review):\n",
    "\n",
    "    # regex to match negation tokens\n",
    "    negation_re = re.compile(\"\"\"(?x)(?:^(?:never|no|nothing|nowhere|noone|none|not|havent|\n",
    "            hasnt|hadnt|cant|couldnt|shouldnt|wont|wouldnt|dont|\n",
    "            doesnt|didnt|isnt|arent|aint)$)|n't\"\"\")\n",
    "\n",
    "    alter_re = re.compile(\"\"\"(?x)(?:^(?:but|however|nevertheless|still|though|tho|yet)$)\"\"\")\n",
    "\n",
    "    neg_review_tokens = []\n",
    "    append_neg = False  # stores whether to add \"_NEG\"\n",
    "\n",
    "    for token in review:\n",
    "\n",
    "        # If append_neg is False\n",
    "        if append_neg == False:\n",
    "\n",
    "            # Check if the current token is a negation\n",
    "            if negation_re.match(token):\n",
    "                append_neg = True\n",
    "\n",
    "        # but if a negation has been previously identified, check if this is an  alteration\n",
    "        elif alter_re.match(token):\n",
    "            append_neg = False\n",
    "\n",
    "        # or if another negation appears\n",
    "        elif negation_re.match(token):\n",
    "            append_neg = False\n",
    "\n",
    "        # and if not then append the suffix\n",
    "        else:\n",
    "            token += \"_NEG\"\n",
    "\n",
    "        # append the new token in the return list\n",
    "        neg_review_tokens.append(token)\n",
    "\n",
    "    return neg_review_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress::   0%|          | 0/99999 [00:00<?, ?it/s]\u001b[A\n",
      "Progress::   4%|▎         | 3716/99999 [00:00<00:02, 37158.53it/s]\u001b[A\n",
      "Progress::   6%|▋         | 6337/99999 [00:00<00:02, 33018.73it/s]\u001b[A\n",
      "Progress::   9%|▉         | 9143/99999 [00:00<00:02, 31349.95it/s]\u001b[A\n",
      "Progress::  12%|█▏        | 11741/99999 [00:00<00:02, 29519.40it/s]\u001b[A\n",
      "Progress::  14%|█▍        | 14309/99999 [00:00<00:03, 28235.97it/s]\u001b[A\n",
      "Progress::  17%|█▋        | 16933/99999 [00:00<00:03, 27601.99it/s]\u001b[A\n",
      "Progress::  20%|█▉        | 19896/99999 [00:00<00:02, 28177.42it/s]\u001b[A\n",
      "Progress::  23%|██▎       | 22581/99999 [00:00<00:02, 27765.38it/s]\u001b[A\n",
      "Progress::  26%|██▌       | 25953/99999 [00:00<00:02, 29318.12it/s]\u001b[A\n",
      "Progress::  30%|██▉       | 29760/99999 [00:01<00:02, 31485.19it/s]\u001b[A\n",
      "Progress::  33%|███▎      | 32879/99999 [00:01<00:02, 30185.61it/s]\u001b[A\n",
      "Progress::  38%|███▊      | 37692/99999 [00:01<00:01, 33985.66it/s]\u001b[A\n",
      "Progress::  41%|████      | 41242/99999 [00:01<00:01, 33831.64it/s]\u001b[A\n",
      "Progress::  45%|████▍     | 44732/99999 [00:01<00:01, 31495.27it/s]\u001b[A\n",
      "Progress::  48%|████▊     | 47989/99999 [00:01<00:01, 27826.16it/s]\u001b[A\n",
      "Progress::  51%|█████     | 51246/99999 [00:01<00:01, 29084.17it/s]\u001b[A\n",
      "Progress::  54%|█████▍    | 54277/99999 [00:01<00:01, 26697.60it/s]\u001b[A\n",
      "Progress::  57%|█████▋    | 57071/99999 [00:01<00:01, 25818.77it/s]\u001b[A\n",
      "Progress::  60%|█████▉    | 59843/99999 [00:02<00:01, 26359.54it/s]\u001b[A\n",
      "Progress::  63%|██████▎   | 62547/99999 [00:02<00:01, 26014.27it/s]\u001b[A\n",
      "Progress::  65%|██████▌   | 65197/99999 [00:02<00:01, 25936.43it/s]\u001b[A\n",
      "Progress::  68%|██████▊   | 67918/99999 [00:02<00:01, 26301.92it/s]\u001b[A\n",
      "Progress::  71%|███████   | 70574/99999 [00:02<00:01, 25664.98it/s]\u001b[A\n",
      "Progress::  73%|███████▎  | 73162/99999 [00:02<00:01, 24024.86it/s]\u001b[A\n",
      "Progress::  76%|███████▌  | 75601/99999 [00:02<00:01, 23787.60it/s]\u001b[A\n",
      "Progress::  79%|███████▉  | 79146/99999 [00:02<00:00, 26387.73it/s]\u001b[A\n",
      "Progress::  82%|████████▏ | 81892/99999 [00:02<00:00, 26450.53it/s]\u001b[A\n",
      "Progress::  85%|████████▍ | 84612/99999 [00:03<00:00, 26646.06it/s]\u001b[A\n",
      "Progress::  87%|████████▋ | 87330/99999 [00:03<00:00, 25342.92it/s]\u001b[A\n",
      "Progress::  90%|████████▉ | 89915/99999 [00:03<00:00, 24762.83it/s]\u001b[A\n",
      "Progress::  93%|█████████▎| 92533/99999 [00:03<00:00, 25170.43it/s]\u001b[A\n",
      "Progress::  95%|█████████▌| 95079/99999 [00:03<00:00, 24912.89it/s]\u001b[A\n",
      "Progress::  98%|█████████▊| 97809/99999 [00:03<00:00, 25581.36it/s]\u001b[A\n",
      "Progress:: 100%|██████████| 99999/99999 [00:03<00:00, 27663.46it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, mentally, inspiring, book, allow...\n",
       "1    [one, must, books, masterpiece, spirituality, ...\n",
       "2    [book, provides, reflection, apply, lifeand, w...\n",
       "3    [first, read, prophet, college, back, sixty, b...\n",
       "4    [timeless, classic, demanding, assuming, title...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_5_df = step_4_df.progress_apply(lambda review: negation_tokenizer(review))\n",
    "step_5_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['delightful',\n",
       " 'read',\n",
       " 'water',\n",
       " 'elephants',\n",
       " 'got',\n",
       " 'one',\n",
       " 'best',\n",
       " 'reads',\n",
       " 'anyone',\n",
       " 'likes',\n",
       " 'animals',\n",
       " 'circuses',\n",
       " 'wonderfully',\n",
       " 'flowing',\n",
       " 'story',\n",
       " 'working',\n",
       " 'circus',\n",
       " 'especially',\n",
       " 'past',\n",
       " 'years',\n",
       " 'one',\n",
       " 'grueling',\n",
       " 'tough',\n",
       " 'jobs',\n",
       " 'tackle',\n",
       " 'sara',\n",
       " 'gruen',\n",
       " 'makes',\n",
       " 'reader',\n",
       " 'smell',\n",
       " 'circus',\n",
       " 'smells',\n",
       " 'taste',\n",
       " 'midway',\n",
       " 'foods',\n",
       " 'ring',\n",
       " 'animals',\n",
       " 'entertain',\n",
       " 'circus',\n",
       " 'since',\n",
       " 'teenager',\n",
       " 'many',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'water',\n",
       " 'elephants',\n",
       " 'took',\n",
       " 'back',\n",
       " 'days',\n",
       " 'reminding',\n",
       " 'things',\n",
       " 'saw',\n",
       " 'smelledhis',\n",
       " 'family',\n",
       " 'placed',\n",
       " 'jacob',\n",
       " 'jankowski',\n",
       " 'home',\n",
       " 'old',\n",
       " 'folks',\n",
       " 'none',\n",
       " 'wanted_NEG',\n",
       " 'take_NEG',\n",
       " 'care_NEG',\n",
       " 'sad_NEG',\n",
       " 'true_NEG',\n",
       " 'jacob_NEG',\n",
       " 'sure_NEG',\n",
       " 'ninety_NEG',\n",
       " 'ninetythree_NEG',\n",
       " 'years_NEG',\n",
       " 'age_NEG',\n",
       " 'knows_NEG',\n",
       " 'age_NEG',\n",
       " 'somewhere_NEG',\n",
       " 'around_NEG',\n",
       " 'range_NEG',\n",
       " 'jacob_NEG',\n",
       " 'hates_NEG',\n",
       " 'old_NEG',\n",
       " 'people_NEG',\n",
       " 'home_NEG',\n",
       " 'hates_NEG',\n",
       " 'food_NEG',\n",
       " 'hates_NEG',\n",
       " 'nurses_NEG',\n",
       " 'treat_NEG',\n",
       " 'like_NEG',\n",
       " 'know_NEG',\n",
       " 'saying_NEG',\n",
       " 'life_NEG',\n",
       " 'jacob_NEG',\n",
       " 'jankowski_NEG',\n",
       " 'story_NEG',\n",
       " 'goes_NEG',\n",
       " 'back_NEG',\n",
       " 'jacob_NEG',\n",
       " 'cornell_NEG',\n",
       " 'college_NEG',\n",
       " 'studying_NEG',\n",
       " 'veterinarian_NEG',\n",
       " 'shy_NEG',\n",
       " 'women_NEG',\n",
       " 'wanted_NEG',\n",
       " 'nothing',\n",
       " 'socially',\n",
       " 'jacob',\n",
       " 'thought',\n",
       " 'must',\n",
       " 'worlds',\n",
       " 'oldest',\n",
       " 'male',\n",
       " 'virgin',\n",
       " 'jacob',\n",
       " 'well',\n",
       " 'schooling',\n",
       " 'one',\n",
       " 'day',\n",
       " 'called',\n",
       " 'class',\n",
       " 'told',\n",
       " 'parents',\n",
       " 'killed',\n",
       " 'automobile',\n",
       " 'accident',\n",
       " 'jacob',\n",
       " 'course',\n",
       " 'crushed',\n",
       " 'mentally',\n",
       " 'physically',\n",
       " 'could',\n",
       " 'nt',\n",
       " 'happening',\n",
       " 'parents',\n",
       " 'paying',\n",
       " 'way',\n",
       " 'college',\n",
       " 'figured',\n",
       " 'could',\n",
       " 'continue',\n",
       " 'education',\n",
       " 'whatever',\n",
       " 'parents',\n",
       " 'left',\n",
       " 'father',\n",
       " 'also',\n",
       " 'veterinarian',\n",
       " 'good',\n",
       " 'practice',\n",
       " 'jacob',\n",
       " 'beside',\n",
       " 'told',\n",
       " 'property',\n",
       " 'parents',\n",
       " 'owned',\n",
       " 'taken',\n",
       " 'funds',\n",
       " 'pay',\n",
       " 'bills',\n",
       " 'turns',\n",
       " 'father',\n",
       " 'bartered',\n",
       " 'customers',\n",
       " 'paid',\n",
       " 'chickens',\n",
       " 'eggs',\n",
       " 'animals',\n",
       " 'whatever',\n",
       " 'moneythis',\n",
       " 'upset',\n",
       " 'jacob',\n",
       " 'much',\n",
       " 'took',\n",
       " 'walking',\n",
       " 'walking',\n",
       " 'came',\n",
       " 'rail',\n",
       " 'track',\n",
       " 'train',\n",
       " 'moving',\n",
       " 'going',\n",
       " 'jump',\n",
       " 'regardless',\n",
       " 'going',\n",
       " 'thus',\n",
       " 'jacob',\n",
       " 'began',\n",
       " 'circus',\n",
       " 'life',\n",
       " 'jumped',\n",
       " 'train',\n",
       " 'met',\n",
       " 'circus',\n",
       " 'performers',\n",
       " 'roustabouts',\n",
       " 'idea',\n",
       " 'lie',\n",
       " 'ahead',\n",
       " 'inclusion',\n",
       " 'circus',\n",
       " 'life',\n",
       " 'difficult',\n",
       " 'circus',\n",
       " 'like',\n",
       " 'young',\n",
       " 'rubes',\n",
       " 'around',\n",
       " 'experienced',\n",
       " 'circus',\n",
       " 'people',\n",
       " 'found',\n",
       " 'almost',\n",
       " 'veterinarian',\n",
       " 'elated',\n",
       " 'one',\n",
       " 'medically',\n",
       " 'care',\n",
       " 'animals',\n",
       " 'gave',\n",
       " 'jacob',\n",
       " 'ticket',\n",
       " 'circus',\n",
       " 'lifeas',\n",
       " 'said',\n",
       " 'originally',\n",
       " 'author',\n",
       " 'makes',\n",
       " 'feel',\n",
       " 'though',\n",
       " 'circus',\n",
       " 'troupe',\n",
       " 'raised',\n",
       " 'tents',\n",
       " 'shows',\n",
       " 'ate',\n",
       " 'food',\n",
       " 'available',\n",
       " 'got',\n",
       " 'paid',\n",
       " 'money',\n",
       " 'running',\n",
       " 'away',\n",
       " 'law',\n",
       " 'one',\n",
       " 'circus',\n",
       " 'caused',\n",
       " 'problem',\n",
       " 'law',\n",
       " 'local',\n",
       " 'authorities',\n",
       " 'traveled',\n",
       " 'circus',\n",
       " 'train',\n",
       " 'never',\n",
       " 'knowing_NEG',\n",
       " 'sure_NEG',\n",
       " 'would_NEG',\n",
       " 'end_NEG',\n",
       " 'putting_NEG',\n",
       " 'circus_NEG',\n",
       " 'owner_NEG',\n",
       " 'top_NEG',\n",
       " 'management_NEG',\n",
       " 'treated_NEG',\n",
       " 'help_NEG',\n",
       " 'like_NEG',\n",
       " 'dirtof_NEG',\n",
       " 'course_NEG',\n",
       " 'much_NEG',\n",
       " 'book_NEG',\n",
       " 'personal_NEG',\n",
       " 'lives_NEG',\n",
       " 'circus_NEG',\n",
       " 'employees_NEG',\n",
       " 'owners_NEG',\n",
       " 'also_NEG',\n",
       " 'circus_NEG',\n",
       " 'obtained_NEG',\n",
       " 'animals_NEG',\n",
       " 'equipment_NEG',\n",
       " 'legally_NEG',\n",
       " 'otherwise_NEG',\n",
       " 'eye_NEG',\n",
       " 'opener_NEG',\n",
       " 'anyone_NEG',\n",
       " 'read_NEG',\n",
       " 'makes_NEG',\n",
       " 'one_NEG',\n",
       " 'wonder_NEG',\n",
       " 'circus_NEG',\n",
       " 'people_NEG',\n",
       " 'existed_NEG',\n",
       " 'days_NEG',\n",
       " 'traveling_NEG',\n",
       " 'living_NEG',\n",
       " 'uncertain_NEG',\n",
       " 'existencethe_NEG',\n",
       " 'story_NEG',\n",
       " 'occasionally_NEG',\n",
       " 'go_NEG',\n",
       " 'back_NEG',\n",
       " 'jacob_NEG',\n",
       " 'home_NEG',\n",
       " 'unhappy_NEG',\n",
       " 'circus_NEG',\n",
       " 'comes_NEG',\n",
       " 'town_NEG',\n",
       " 'sets_NEG',\n",
       " 'right_NEG',\n",
       " 'next_NEG',\n",
       " 'home_NEG',\n",
       " 'making_NEG',\n",
       " 'jacob_NEG',\n",
       " 'excited_NEG',\n",
       " 'close_NEG',\n",
       " 'circus_NEG',\n",
       " 'even_NEG',\n",
       " 'though',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'worked',\n",
       " 'younger',\n",
       " 'days',\n",
       " 'passed',\n",
       " 'slowly',\n",
       " 'waited',\n",
       " 'family',\n",
       " 'come',\n",
       " 'take',\n",
       " 'big',\n",
       " 'visit',\n",
       " 'big',\n",
       " 'topi',\n",
       " 'doubt',\n",
       " 'anyone',\n",
       " 'could',\n",
       " 'read',\n",
       " 'book',\n",
       " 'without',\n",
       " 'coming',\n",
       " 'away',\n",
       " 'great',\n",
       " 'understanding',\n",
       " 'old',\n",
       " 'circus',\n",
       " 'days',\n",
       " 'meant',\n",
       " 'people',\n",
       " 'worked',\n",
       " 'hard',\n",
       " 'life',\n",
       " 'know',\n",
       " 'sara',\n",
       " 'gruen',\n",
       " 'put',\n",
       " 'much',\n",
       " 'time',\n",
       " 'effort',\n",
       " 'research',\n",
       " 'water',\n",
       " 'elephants',\n",
       " 'enjoy',\n",
       " 'book',\n",
       " 'entertain',\n",
       " 'educate',\n",
       " 'time']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_5_df[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
