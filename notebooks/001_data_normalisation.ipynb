{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "import plotly \n",
    "import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import cufflinks as cf\n",
    "print(cf.__version__)\n",
    "# Configure cufflings \n",
    "cf.set_config_file(offline=False, world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download()\n",
    "# !pip install autocorrect\n",
    "from autocorrect import spell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For monitoring duration of pandas processes\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# To avoid RuntimeError: Set changed size during iteration\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# can also groupby:\n",
    "# df.groupby(0).progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = getDF('/Users/falehalrashidi/Downloads/reviews_Books_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Adam</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Wonderful!</td>\n",
       "      <td>1355616000</td>\n",
       "      <td>12 16, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>adead_poet@hotmail.com \"adead_poet@hotmail.com\"</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>close to god</td>\n",
       "      <td>1071100800</td>\n",
       "      <td>12 11, 2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Ahoro Blethends \"Seriously\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Must Read for Life Afficianados</td>\n",
       "      <td>1390003200</td>\n",
       "      <td>01 18, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alan Krug</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Timeless for every good and bad time in your l...</td>\n",
       "      <td>1317081600</td>\n",
       "      <td>09 27, 2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Alaturka</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>A Modern Rumi</td>\n",
       "      <td>1033948800</td>\n",
       "      <td>10 7, 2002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                      reviewerName helpful  \\\n",
       "0                                             Adam  [0, 0]   \n",
       "1  adead_poet@hotmail.com \"adead_poet@hotmail.com\"  [0, 2]   \n",
       "2                      Ahoro Blethends \"Seriously\"  [0, 0]   \n",
       "3                                        Alan Krug  [0, 0]   \n",
       "4                                         Alaturka  [7, 9]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...      5.0   \n",
       "1  This is one my must have books. It is a master...      5.0   \n",
       "2  This book provides a reflection that you can a...      5.0   \n",
       "3  I first read THE PROPHET in college back in th...      5.0   \n",
       "4  A timeless classic.  It is a very demanding an...      5.0   \n",
       "\n",
       "                                             summary  unixReviewTime  \\\n",
       "0                                         Wonderful!      1355616000   \n",
       "1                                       close to god      1071100800   \n",
       "2                    Must Read for Life Afficianados      1390003200   \n",
       "3  Timeless for every good and bad time in your l...      1317081600   \n",
       "4                                      A Modern Rumi      1033948800   \n",
       "\n",
       "    reviewTime  \n",
       "0  12 16, 2012  \n",
       "1  12 11, 2003  \n",
       "2  01 18, 2014  \n",
       "3  09 27, 2011  \n",
       "4   10 7, 2002  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  \n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]  \n",
       "1  This is one my must have books. It is a master...  [0, 2]  \n",
       "2  This book provides a reflection that you can a...  [0, 0]  \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]  \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df[['reviewerID','asin','reviewText','helpful']]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8898041"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 8898041/8898041 [00:06<00:00, 1388667.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>denom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  denom  \n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]      0  \n",
       "1  This is one my must have books. It is a master...  [0, 2]      2  \n",
       "2  This book provides a reflection that you can a...  [0, 0]      0  \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]      0  \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]      9  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create new Column for the denominator\n",
    "df2 = df1.assign(denom = df1['helpful'].progress_apply(lambda enum_denom:enum_denom[1]))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>helpful</th>\n",
       "      <th>denom</th>\n",
       "      <th>uniqueKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "      <td>[0, 2]</td>\n",
       "      <td>2</td>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0</td>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "      <td>[7, 9]</td>\n",
       "      <td>9</td>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerID        asin  \\\n",
       "0  A10000012B7CGYKOMPQ4L  000100039X   \n",
       "1         A2S166WSCFIFP5  000100039X   \n",
       "2         A1BM81XB4QHOA3  000100039X   \n",
       "3         A1MOSTXNIO5MPJ  000100039X   \n",
       "4         A2XQ5LZHTD4AFT  000100039X   \n",
       "\n",
       "                                          reviewText helpful  denom  \\\n",
       "0  Spiritually and mentally inspiring! A book tha...  [0, 0]      0   \n",
       "1  This is one my must have books. It is a master...  [0, 2]      2   \n",
       "2  This book provides a reflection that you can a...  [0, 0]      0   \n",
       "3  I first read THE PROPHET in college back in th...  [0, 0]      0   \n",
       "4  A timeless classic.  It is a very demanding an...  [7, 9]      9   \n",
       "\n",
       "                           uniqueKey  \n",
       "0  A10000012B7CGYKOMPQ4L##000100039X  \n",
       "1         A2S166WSCFIFP5##000100039X  \n",
       "2         A1BM81XB4QHOA3##000100039X  \n",
       "3         A1MOSTXNIO5MPJ##000100039X  \n",
       "4         A2XQ5LZHTD4AFT##000100039X  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Uniquekey Column\n",
    "df3 = df2.assign(uniqueKey = df['reviewerID'].str.cat(df['asin'].values.astype(str), sep='##'))\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey  \\\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X   \n",
       "1         A2S166WSCFIFP5##000100039X   \n",
       "2         A1BM81XB4QHOA3##000100039X   \n",
       "3         A1MOSTXNIO5MPJ##000100039X   \n",
       "4         A2XQ5LZHTD4AFT##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  Spiritually and mentally inspiring! A book tha...  \n",
       "1  This is one my must have books. It is a master...  \n",
       "2  This book provides a reflection that you can a...  \n",
       "3  I first read THE PROPHET in college back in th...  \n",
       "4  A timeless classic.  It is a very demanding an...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keep only the columns necessary for the normalisation\n",
    "df4 = df3[['uniqueKey', 'reviewText']]\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was necessary due to weird keyErrors that followed after trying to process the reviewText as a `pandas.DataFrame` and not as `pandas.Series`. After experimenting with both, I found that `pandas.Series.apply` is faster than `pandas.DataFrame.apply` and so I will hence work with `pandas.Series`. \n",
    "\n",
    "The assumption I require to make at this point before I follow is that `pandas` will not change the index of the reviews as those are being processed by my code and that in the end of my processing I will be able to re-associate those reviews with their **uniqueKey**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X\n",
       "1         A2S166WSCFIFP5##000100039X\n",
       "2         A1BM81XB4QHOA3##000100039X\n",
       "3         A1MOSTXNIO5MPJ##000100039X\n",
       "4         A2XQ5LZHTD4AFT##000100039X"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueKey_series_df = df4[['uniqueKey']]\n",
    "uniqueKey_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 8898041/8898041 [00:08<00:00, 1010648.65it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spiritually and mentally inspiring! A book tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is one my must have books. It is a master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This book provides a reflection that you can a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I first read THE PROPHET in college back in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A timeless classic.  It is a very demanding an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  Spiritually and mentally inspiring! A book tha...\n",
       "1  This is one my must have books. It is a master...\n",
       "2  This book provides a reflection that you can a...\n",
       "3  I first read THE PROPHET in college back in th...\n",
       "4  A timeless classic.  It is a very demanding an..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df = pd.DataFrame(df4['reviewText'].progress_apply(lambda review: review.split(\"\\n\")[0]))\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation\n",
    "<span style=\"color:red\">**NOTICE:** As I am in a hurry to complete the first pipeline, I will only work with the first 100k reviews.</span>\n",
    "\n",
    "* Tokenization <span style=\"color:blue\"> DONE </span>\n",
    "* Convert All Tokens to Lowercase <span style=\"color:blue\"> DONE </span>\n",
    "* Eliminate Punctuation <span style=\"color:blue\"> DONE </span>\n",
    "* Remove Stop Words <span style=\"color:blue\"> DONE </span>\n",
    "* Changing Numbers into Words <span style=\"color:blue\"> DONE </span>\n",
    "* Expand Abbreviations <span style=\"color:red\"> NOT AS EASY AS I THOUGHT AND DOES NOT ADD MUCH VALUE (Ask Stasha's opinion)</span> \n",
    "* Correct Spelling <span style=\"color:red\"> TOO SLOW (10h for 100k reviews)-->SO WONT DO</span>\n",
    "* Substituting Tokens with Synonyms <span style=\"color:green\"> TO DO</span>\n",
    "* Semantical Marking of Negatives <span style=\"color:blue\"> DONE (Ask Stasha's opinion) </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [16:58<00:00, 98.14it/s]   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [Spiritually, and, mentally, inspiring, A, boo...\n",
       "1    [This, is, one, my, must, have, books, It, is,...\n",
       "2    [This, book, provides, a, reflection, that, yo...\n",
       "3    [I, first, read, THE, PROPHET, in, college, ba...\n",
       "4    [A, timeless, classic, It, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "tokenizer=RegexpTokenizer('[\\'\\w\\-]+',gaps=False)\n",
    "\n",
    "step_0_df = reviews_df['reviewText'][0:99999].progress_apply(lambda review: tokenizer.tokenize(review))\n",
    "step_0_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Tokens to Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def convert_to_lowercase(review):\n",
    "\n",
    "    for i in range(len(review)):\n",
    "        review[i] = review[i].lower()\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 58665.24it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, a, boo...\n",
       "1    [this, is, one, my, must, have, books, it, is,...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, it, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_1_df = step_0_df.progress_apply(lambda review: convert_to_lowercase(review))\n",
    "step_1_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def eliminate_punctuation(review, regex):\n",
    "    new_review = []\n",
    "    for token in review:\n",
    "        new_token = regex.sub(u'', token)\n",
    "        if not new_token == u'':\n",
    "            new_review.append(new_token)\n",
    "    return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:05<00:00, 19761.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, a, boo...\n",
       "1    [this, is, one, my, must, have, books, it, is,...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, it, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex=re.compile('[%s]' % re.escape(string.punctuation))\n",
    "\n",
    "step_2_df = step_1_df.progress_apply(lambda review: eliminate_punctuation(review, regex))\n",
    "step_2_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Numbers into Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import inflect\n",
    "p = inflect.engine()\n",
    "\n",
    "def numStringToWord(review, p):\n",
    "\n",
    "    for i in range(len(review)):\n",
    "        if(review[i].isdigit()):\n",
    "            review[i] = p.number_to_words(review[i])\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:03<00:00, 27708.38it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, a, boo...\n",
       "1    [this, is, one, my, must, have, books, it, is,...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, it, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_3_df = step_2_df.progress_apply(lambda review: numStringToWord(review, p))\n",
    "step_3_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct Spelling\n",
    "It turns out that this is a very expensive operation to run at this stage. In addition to this, the solution below by which I am able to substitue synonyms, also works as a spellchecker and hence applying a spell-checker directly and at this point is both non-efficient and seems to also be redundant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from autocorrect import spell\n",
    "\n",
    "# def spellCheck(review):\n",
    "\n",
    "#     for i in range(len(review)):\n",
    "#         review[i] = spell(review[i])\n",
    "#     return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# step_5_df = step_4_df.progress_apply(lambda review: spellCheck(review))\n",
    "# step_5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substituting Tokens with Synonyms\n",
    "Replacing words with synonyms is a very tricky operation. In fact,synonyms are a huge and open area of work in natural language processing.\n",
    "\n",
    "The problem is multifaceted and mostly derives from the fact that for any single word, and especially for adjectives, there is no one single adjective to replace it with. Suppose for instance that we rely on a solution based on the `PyDictionary` library. In the below example, you can clearly see that there are multiple words to be chosen for a certain noun: \n",
    "\n",
    "```python\n",
    ">>> from PyDictionary import PyDictionary\n",
    "\n",
    ">>> dictionary=PyDictionary()\n",
    "print (dictionary.synonym(\"Life\"))\n",
    "['heart', 'growth', 'soul', 'activity', 'get-up-and-go']\n",
    "```\n",
    "It is therefore necessary that one defines a way by which a certain alternative is chosen from the resulting list. In `NLP` a list of synonyms is commonly reffered to as `synset`. \n",
    "\n",
    "A naive way to go about solving this problem is to choose the most common member in the set. The `nltk` will let you build a frequency table in just a few lines of code ([link](https://stackoverflow.com/questions/38233145/nltk-most-common-synonym-wordnet-for-each-word)). \n",
    "```python\n",
    ">>> from nltk.corpus import brown\n",
    ">>> freqs = nltk.FreqDist(w.lower() for w in brown.words())\n",
    ">>> print(freqs[\"valued\"])\n",
    "14\n",
    "```\n",
    "But, in turn, one has to also figure out how to define the \"most common member\" in the set. This could be based on measuring the each members appearance frequence in the whole corpus. However, this would also be problematic for number of reasons; the main one relates to the semantical meaning of synonyms.\n",
    "\n",
    "Synomyms are not semantically equal words in terms of their meaning. For instance, in the previous example, \"growth\" appears  to be a synonym for \"life\", yet, though related, the two words have different interpretations. Furthermore, if we take each word as a signleton and try to interpret its meaning irrespective of the context it is being used in, it is quite possible that our interpretation will deviade from the words intended meaning. The general point is that the context in which a word is used is also important. If we rely on the whole corpus to define the importance of a word over others then we may end up replacing words in book reviews, not based on how often those words are used with respect to the book at hand but with respect to the whole corpus of reviews for all kinds of books. \n",
    "\n",
    "A more sophisticated approach would focus on identifying word frequencies within the scope of reviews for a certain book. For that, one would need to:\n",
    "\n",
    "1. Construct a set of review corpuses, one for every book;\n",
    "2. Create a dictionary of frequencies of words for each of these corpuses, and;\n",
    "3. Use the dictionary to choose the word with the highest frequency in a synset.\n",
    "\n",
    "In addition to the above problem, one needs to tackle another difficulty. The point of replacing sysonyms is to reduce the vocabulary of a text. By compressing the vocabulary without losing meaning, you can save memory in cases such as frequency analysis and text indexing (https://en.wikipedia.org/wiki/Frequency_analysis). Vocabulary reduction can also increase the occurrence of significant collocations. But this can only be achieved as long a the same synonym is consistently chosen from a `synset` and the semantical meaning of the word it replaces is not distorted. Let us illustrate why this is a complex task. Following on the previous example:\n",
    "```python\n",
    ">>> print (dictionary.synonym(\"growth\"))\n",
    "['prosperity', 'success', 'advance', 'hike', 'rise']\n",
    ">>> print (dictionary.synonym(\"success\"))\n",
    "['prosperity', 'advance', 'achievement', 'win', 'accomplishment']\n",
    ">>> print (dictionary.synonym(\"prosperity\"))\n",
    "['wealth', 'success', 'accomplishment', 'riches', 'expansion']\n",
    ">>> print (dictionary.synonym(\"advance\"))\n",
    "['forward', 'leading', 'prior', 'first', 'beforehand']\n",
    "```\n",
    "\n",
    "Notice, that \"growth\" and \"success\" don't share the exact same `synset`, so it is possible that while one synnonym is chosen for the first, another is chosen for the second. This incosistency will reduce the chances of minimising the corpus' vocabulary. Furhtermore, suppose that it just so happens that both words are replaced with one of the commonly shared synonyms--that is either 'prosperity' or 'advance'--then, if it is propserity, then propserity should not be replaced when encountered at all!\n",
    "\n",
    "This problem, though complicated, can be handle with the developement of a well-thought algorithm. However, if the objective is to replace each and every word in the dataset, it will still fail as it is very likely that the solution will not be efficient or, worse, tractable. At the same time, it is quite possible that it will distort the text it originated from. To counter these problems, one can only apply this solution only on certain kinds of words, and specifically on adjectives. This approach offers two  significant advantages:\n",
    "\n",
    "1. It reduces the application scope to something more tractable, and;\n",
    "2. Minimises the risk of distorting meaning as adjectives and their `synsets` are more strictly defined and their meaning is unlikely to significantly deviate from the original word.\n",
    "\n",
    "The above points can be justified simply by looking at the synsets of two random synonyms: \n",
    "```python\n",
    ">>> print (dictionary.synonym(\"hard\"))\n",
    "['solid', 'strong', 'tough', 'concentrated', 'callous']\n",
    ">>> print (dictionary.synonym(\"tough\"))\n",
    "['tenacious', 'vigorous', 'stiff', 'solid', 'hard']\n",
    "```\n",
    "\n",
    "As such, replacing of synonyms will be postponed until after POS-tagging is applied in the next section. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Negations with Antonyms\n",
    "The opposite of synonym replacement is antonym replacement. An antonym is a word that has the opposite meaning of another word. This time, instead of creating custom word mappings, we can use WordNet to replace words with unambiguous antonyms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AntonymReplacer(object):\n",
    "    def replace(self, token, pos=None):\n",
    "        antonyms = set()\n",
    "        for syn in wordnet.synsets(token, pos=pos):\n",
    "            for lemma in syn.lemmas():\n",
    "                for antonym in lemma.antonyms():\n",
    "                    antonyms.add(antonym.name())\n",
    "        if len(antonyms) == 1:\n",
    "            return antonyms.pop()\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def replace_negations(self, review):\n",
    "        i, l = 0, len(review)\n",
    "        tokens = []\n",
    "        while i<l:\n",
    "            token = review[i]\n",
    "            if token == 'not' and i+1 <l:\n",
    "                ant = self.replace(review[i+1])\n",
    "                if ant:\n",
    "                    tokens.append(ant)\n",
    "                    i += 2\n",
    "                    continue\n",
    "            tokens.append(token)\n",
    "            i += 1\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lets see an example\n",
    "replacer = AntonymReplacer()\n",
    "replacer.replace(\"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'beautify'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer.replace(\"uglify\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "review = [\"lets\",\"not\",\"uglify\",\"our\",\"code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lets', 'beautify', 'our', 'code']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacer.replace_negations(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:07<00:00, 12996.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, and, mentally, inspiring, a, boo...\n",
       "1    [this, is, one, my, must, have, books, it, is,...\n",
       "2    [this, book, provides, a, reflection, that, yo...\n",
       "3    [i, first, read, the, prophet, in, college, ba...\n",
       "4    [a, timeless, classic, it, is, a, very, demand...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_4_df = step_3_df.progress_apply(lambda review: replacer.replace_negations(review))\n",
    "step_4_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Remove Stop Words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    return [token for token in review if not token in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 67163.46it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually, mentally, inspiring, book, allow...\n",
       "1    [one, must, books, masterpiece, spirituality, ...\n",
       "2    [book, provides, reflection, apply, life, way,...\n",
       "3    [first, read, prophet, college, back, 60s, boo...\n",
       "4    [timeless, classic, demanding, assuming, title...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_5_df = step_4_df.progress_apply(lambda review: remove_stopwords(review))\n",
    "step_5_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOIN normalised reviews with their original keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "      <td>[spiritually, mentally, inspiring, book, allow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "      <td>[one, must, books, masterpiece, spirituality, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "      <td>[book, provides, reflection, apply, life, way,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "      <td>[first, read, prophet, college, back, 60s, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>[timeless, classic, demanding, assuming, title...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey  \\\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X   \n",
       "1         A2S166WSCFIFP5##000100039X   \n",
       "2         A1BM81XB4QHOA3##000100039X   \n",
       "3         A1MOSTXNIO5MPJ##000100039X   \n",
       "4         A2XQ5LZHTD4AFT##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  [spiritually, mentally, inspiring, book, allow...  \n",
       "1  [one, must, books, masterpiece, spirituality, ...  \n",
       "2  [book, provides, reflection, apply, life, way,...  \n",
       "3  [first, read, prophet, college, back, 60s, boo...  \n",
       "4  [timeless, classic, demanding, assuming, title...  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_keyed_reviews = pd.concat([uniqueKey_series_df[0:99999], step_5_df], axis=1);\n",
    "tokenized_keyed_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_keyed_reviews.to_csv(\"../data/interim/001_normalised_keyed_reviews_100k_sample.csv\", sep='\\t', header=True, index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_keyed_reviews[0:99].to_csv(\"../data/interim/001_normalised_keyed_reviews_100_rows_sample.csv\", sep='\\t', header=True, index=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## END_OF_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
