{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pos-Tagging & Feature Extraction\n",
    "Following normalisation, we can now proceed to the process of pos-tagging and feature extraction. Let's start with pos-tagging."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-tagging\n",
    "Part-of-speech tagging is one of the most important text analysis tasks used to classify words into their part-of-speech and label them according the tagset which is a collection of tags used for the pos tagging. Part-of-speech tagging also known as word classes or lexical categories.\n",
    "\n",
    "The `nltk` library provides its own pre-trained `POS-tagger`. Let's see how it is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A10000012B7CGYKOMPQ4L##000100039X</td>\n",
       "      <td>['spiritually', 'mentally', 'inspiring', 'book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A2S166WSCFIFP5##000100039X</td>\n",
       "      <td>['one', 'must', 'books', 'masterpiece', 'spiri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1BM81XB4QHOA3##000100039X</td>\n",
       "      <td>['book', 'provides', 'reflection', 'apply', 'l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A1MOSTXNIO5MPJ##000100039X</td>\n",
       "      <td>['first', 'read', 'prophet', 'college', 'back'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>['timeless', 'classic', 'demanding', 'assuming...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           uniqueKey  \\\n",
       "0  A10000012B7CGYKOMPQ4L##000100039X   \n",
       "1         A2S166WSCFIFP5##000100039X   \n",
       "2         A1BM81XB4QHOA3##000100039X   \n",
       "3         A1MOSTXNIO5MPJ##000100039X   \n",
       "4         A2XQ5LZHTD4AFT##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  ['spiritually', 'mentally', 'inspiring', 'book...  \n",
       "1  ['one', 'must', 'books', 'masterpiece', 'spiri...  \n",
       "2  ['book', 'provides', 'reflection', 'apply', 'l...  \n",
       "3  ['first', 'read', 'prophet', 'college', 'back'...  \n",
       "4  ['timeless', 'classic', 'demanding', 'assuming...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df0 = pd.read_csv(\"../data/interim/001_normalised_keyed_reviews_100k_sample.csv\", sep=\"\\t\", low_memory=False)\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For monitoring duration of pandas processes\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# To avoid RuntimeError: Set changed size during iteration\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# can also groupby:\n",
    "# df.groupby(0).progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_text_to_list(review):\n",
    "    return review.replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Progress::   0%|          | 0/99999 [00:00<?, ?it/s]\u001b[A\n",
      "Progress::   9%|▊         | 8722/99999 [00:00<00:01, 86814.60it/s]\u001b[A\n",
      "Progress::  16%|█▌        | 15759/99999 [00:00<00:01, 81123.16it/s]\u001b[A\n",
      "Progress::  23%|██▎       | 23296/99999 [00:00<00:00, 79294.07it/s]\u001b[A\n",
      "Progress::  32%|███▏      | 32201/99999 [00:00<00:00, 81987.82it/s]\u001b[A\n",
      "Progress::  42%|████▏     | 42196/99999 [00:00<00:00, 86658.10it/s]\u001b[A\n",
      "Progress::  50%|████▉     | 49521/99999 [00:00<00:00, 81953.00it/s]\u001b[A\n",
      "Progress::  57%|█████▋    | 56831/99999 [00:00<00:00, 77467.55it/s]\u001b[A\n",
      "Progress::  64%|██████▍   | 64009/99999 [00:00<00:00, 75179.05it/s]\u001b[A\n",
      "Progress::  71%|███████   | 71154/99999 [00:00<00:00, 74011.18it/s]\u001b[A\n",
      "Progress::  78%|███████▊  | 78291/99999 [00:01<00:00, 72865.32it/s]\u001b[A\n",
      "\n",
      "Progress::  86%|████████▌ | 85804/99999 [00:01<00:00, 29241.90it/s]\u001b[A\n",
      "Progress::  93%|█████████▎| 93204/99999 [00:01<00:00, 35723.48it/s]\u001b[A\n",
      "Progress:: 100%|█████████▉| 99970/99999 [00:01<00:00, 41616.41it/s]\u001b[A\n",
      "Progress:: 100%|██████████| 99999/99999 [00:01<00:00, 54619.42it/s]\u001b[A"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [spiritually,  mentally,  inspiring,  book,  a...\n",
       "1    [one,  must,  books,  masterpiece,  spirituali...\n",
       "2    [book,  provides,  reflection,  apply,  life, ...\n",
       "3    [first,  read,  prophet,  college,  back,  60s...\n",
       "4    [timeless,  classic,  demanding,  assuming,  t...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert \"reviewText\" field to back to list\n",
    "df0['reviewText'] = df0['reviewText'].astype(str)\n",
    "df0['reviewText'] = df0['reviewText'].progress_apply(lambda text: convert_text_to_list(text));\n",
    "df0['reviewText'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.2.4'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow this link for more info on the tagger: https://nlp.stanford.edu/software/tagger.shtml#History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import StanfordPOSTagger\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# import os\n",
    "# os.getcwd()\n",
    "\n",
    "# Add the jar and model via their path (instead of setting environment variables):\n",
    "jar = '../models/stanford-postagger-full-2017-06-09/stanford-postagger.jar'\n",
    "model = '../models/stanford-postagger-full-2017-06-09/models/english-left3words-distsim.tagger'\n",
    "\n",
    "pos_tagger = StanfordPOSTagger(model, jar, encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('What', 'WP'), (\"'s\", 'VBZ'), ('the', 'DT'), ('airspeed', 'NN'), ('of', 'IN'), ('an', 'DT'), ('unladen', 'JJ'), ('swallow', 'VB'), ('?', '.')]\n"
     ]
    }
   ],
   "source": [
    "# Example\n",
    "text = pos_tagger.tag(word_tokenize(\"What's the airspeed of an unladen swallow ?\"))\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pos_tag(review):\n",
    "    if(len(review)>0):\n",
    "        return pos_tagger.tag(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nltk` provides documentation for each tag, which can be queried using the tag, e.g., `nltk.help.upenn_tagset(‘RB’)`, or a regular expression. `nltk` also provides batch pos-tagging method for document pos-tagging:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 50/50 [00:42<00:00,  1.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(spiritually, RB), (mentally, RB), (inspiring...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(one, PRP), (must, MD), (books, NNS), (master...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(book, NN), (provides, VBZ), (reflection, NN)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(first, RB), (read, VB), (prophet, NN), (coll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(timeless, JJ), (classic, JJ), (demanding, VB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  [(spiritually, RB), (mentally, RB), (inspiring...\n",
       "1  [(one, PRP), (must, MD), (books, NNS), (master...\n",
       "2  [(book, NN), (provides, VBZ), (reflection, NN)...\n",
       "3  [(first, RB), (read, VB), (prophet, NN), (coll...\n",
       "4  [(timeless, JJ), (classic, JJ), (demanding, VB..."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_df = pd.DataFrame(df0['reviewText'].progress_apply(lambda review: pos_tag(review)))\n",
    "tagged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('timeless', 'JJ'),\n",
       " ('classic', 'JJ'),\n",
       " ('years', 'NNS'),\n",
       " ('ive', 'JJ'),\n",
       " ('given', 'VBN'),\n",
       " ('gift', 'NN'),\n",
       " ('times', 'NNS'),\n",
       " ('count', 'VBP'),\n",
       " ('continue', 'VB'),\n",
       " ('addresses', 'NNS'),\n",
       " ('real', 'JJ'),\n",
       " ('life', 'NN'),\n",
       " ('issues', 'NNS'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('way', 'NN'),\n",
       " ('makes', 'VBZ'),\n",
       " ('us', 'PRP'),\n",
       " ('reexamine', 'VB'),\n",
       " ('attitude', 'NN'),\n",
       " ('see', 'VB'),\n",
       " ('happens', 'VBZ'),\n",
       " ('lives', 'NNS'),\n",
       " ('easy', 'JJ'),\n",
       " ('read', 'NN')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_df['reviewText'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of all possible tags appears below:\n",
    "\n",
    "| Tag  | Description                              |\n",
    "|------|------------------------------------------|\n",
    "| CC   | Coordinating conjunction                 |\n",
    "| CD   | Cardinal number                          |\n",
    "| DT   | Determiner                               |\n",
    "| EX   | ExistentialĘthere                        |\n",
    "| FW   | Foreign word                             |\n",
    "| IN   | Preposition or subordinating conjunction |\n",
    "| JJ   | Adjective                                |\n",
    "| JJR  | Adjective, comparative                   |\n",
    "| JJS  | Adjective, superlative                   |\n",
    "| LS   | List item marker                         |\n",
    "| MD   | Modal                                    |\n",
    "| NN   | Noun, singular or mass                   |\n",
    "| NNS  | Noun, plural                             |\n",
    "| NNP  | Proper noun, singular                    |\n",
    "| NNPS | Proper noun, plural                      |\n",
    "| PDT  | Predeterminer                            |\n",
    "| POS  | Possessive ending                        |\n",
    "| PRP  | Personal pronoun                         |\n",
    "| PRP* | Possessive pronoun                       |\n",
    "| RB   | Adverb                                   |\n",
    "| RBR  | Adverb, comparative                      |\n",
    "| RBS  | Adverb, superlative                      |\n",
    "| RP   | Particle                                 |\n",
    "| SYM  | Symbol                                   |\n",
    "| TO   | to                                       |\n",
    "| UH   | Interjection                             |\n",
    "| VB   | Verb, base form                          |\n",
    "| VBD  | Verb, past tense                         |\n",
    "| VBG  | Verb, gerund or present participle       |\n",
    "| VBN  | Verb, past participle                    |\n",
    "| VBP  | Verb, non-3rd person singular present    |\n",
    "| VBZ  | Verb, 3rd person singular present        |\n",
    "| WDT  | Wh-determiner                            |\n",
    "| WP   | Wh-pronoun                               |\n",
    "| WP*  | Possessive wh-pronoun                    |\n",
    "| WRB  | Wh-adverb                                |\n",
    "\n",
    "Notice: where you see `*` replace with `$`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Join with Original Key and Persist Locally to avoid RE-processing\n",
    "uniqueKey_series_df = df0[['uniqueKey']]\n",
    "uniqueKey_series_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tagged_keyed_reviews = pd.concat([uniqueKey_series_df, tagged_df], axis=1);\n",
    "pos_tagged_keyed_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tagged_keyed_reviews.to_csv(\"../data/interim/002_pos_tagged_keyed_reviews.csv\", sep='\\t', header=True, index=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Nouns\n",
    "Nouns generally refer to people, places, things, or concepts, e.g.: woman, Scotland, book, intelligence. Nouns can appear after determiners and adjectives, and can be the subject or object of the verb.\n",
    "\n",
    "The simplified noun tags are `N` for common nouns like book, and `NP` for proper nouns like Scotland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun_collector(word_tag_list):\n",
    "    if(len(word_tag_list)>0):\n",
    "        return [word for (word, tag) in word_tag_list if tag in {'NN', 'NNS', 'NNP', 'NNPS'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns_df = pd.DataFrame(tagged_df['reviewText'].progress_apply(lambda review: noun_collector(review)))\n",
    "nouns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_df[\"reviewText\"][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['reviewText'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
