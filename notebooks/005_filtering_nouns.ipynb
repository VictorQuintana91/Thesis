{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For monitoring duration of pandas processes\n",
    "from tqdm import tqdm, tqdm_pandas\n",
    "\n",
    "# To avoid RuntimeError: Set changed size during iteration\n",
    "tqdm.monitor_interval = 0\n",
    "\n",
    "# Register `pandas.progress_apply` and `pandas.Series.map_apply` with `tqdm`\n",
    "# (can use `tqdm_gui`, `tqdm_notebook`, optional kwargs, etc.)\n",
    "tqdm.pandas(desc=\"Progress:\")\n",
    "\n",
    "# Now you can use `progress_apply` instead of `apply`\n",
    "# and `progress_map` instead of `map`\n",
    "# can also groupby:\n",
    "# df.groupby(0).progress_apply(lambda x: x**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df0 = pd.read_pickle('../data/interim/004_synonyms_grouped_1k.p')\n",
    "df0 = pd.read_pickle('../data/interim/002_keyed_nouns.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>[timeless,  gibran,  backs,  content,  means, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN##000100039X</td>\n",
       "      <td>[ prophet,  kahlil,  gibran,  thirty,  years, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3##000100039X</td>\n",
       "      <td>[ first,  books,  recall,  collection,  gibran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65##000100039X</td>\n",
       "      <td>[prophet,  kahlil,  work,  world,  million,  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV##000100039X</td>\n",
       "      <td>[gibran,  khalil,  gibran,  born,  one thousan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    uniqueKey  \\\n",
       "0  A2XQ5LZHTD4AFT##000100039X   \n",
       "1   AF7CSSGV93RXN##000100039X   \n",
       "2  A1NPNGWBVD9AK3##000100039X   \n",
       "3  A3IS4WGMFR4X65##000100039X   \n",
       "4   AWLFVCT9128JV##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  [timeless,  gibran,  backs,  content,  means, ...  \n",
       "1  [ prophet,  kahlil,  gibran,  thirty,  years, ...  \n",
       "2  [ first,  books,  recall,  collection,  gibran...  \n",
       "3  [prophet,  kahlil,  work,  world,  million,  c...  \n",
       "4  [gibran,  khalil,  gibran,  born,  one thousan...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary_df00 = pd.read_pickle('../data/interim/003_dictionary.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822604"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary_df00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>1502803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>one</td>\n",
       "      <td>639620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>read</td>\n",
       "      <td>467228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>386404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>365799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     word  frequency\n",
       "0    book    1502803\n",
       "1     one     639620\n",
       "2    read     467228\n",
       "3    like     386404\n",
       "4   story     365799"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df00.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The idea\n",
    "Words that only appear once cannot be frequent words even in their own context; so they will be filtered out. Then lets calculate the average frequency for the remaining words--remember; this dictionary does not only concern nouns.\n",
    "\n",
    "<span style=\"color:red\"> Notice: grouping of noun synonyms done in `004_grouping_domain_synonyms` is repeated here once filtering out nouns is applied, since it will take far less time to be applied on the whole dataset once the latter is filter (`004_grouping_domain_synonyms` was aplied only on 1k reviews)  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.550540e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.394970e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.586737e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.200000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.100000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.502803e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          frequency\n",
       "count  1.550540e+05\n",
       "mean   5.394970e+02\n",
       "std    6.586737e+03\n",
       "min    6.000000e+00\n",
       "25%    1.000000e+01\n",
       "50%    2.200000e+01\n",
       "75%    9.100000e+01\n",
       "max    1.502803e+06"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df00.loc[dictionary_df00['frequency'] > 5].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "172284"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df00['word'].loc[dictionary_df00['frequency'] > 4].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gt4_dictionary_df01 = dictionary_df00.loc[dictionary_df00['frequency'] > 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.722840e+05\n",
       "mean     4.860424e+02\n",
       "std      6.250750e+03\n",
       "min      5.000000e+00\n",
       "25%      8.000000e+00\n",
       "50%      1.800000e+01\n",
       "75%      7.400000e+01\n",
       "max      1.502803e+06\n",
       "Name: frequency, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary_df00['frequency'].loc[dictionary_df00['frequency'] > 4].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47864"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use threshold for first quantile\n",
    "final_dic = gt4_dictionary_df01.loc[dictionary_df00['frequency'] < 9]\n",
    "len(final_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 47864/47864 [00:00<00:00, 1165060.10it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124420</th>\n",
       "      <td>culturebound</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124421</th>\n",
       "      <td>gilded</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124422</th>\n",
       "      <td>adlibbing</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124423</th>\n",
       "      <td>autoread</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124424</th>\n",
       "      <td>thenardier</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 word  frequency  normalised\n",
       "124420   culturebound          8    0.016461\n",
       "124421         gilded          8    0.016461\n",
       "124422      adlibbing          8    0.016461\n",
       "124423       autoread          8    0.016461\n",
       "124424     thenardier          8    0.016461"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dic_df01 = final_dic.assign(normalised = final_dic['frequency'].progress_apply(lambda frequency:frequency/486))\n",
    "final_dic_df01.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin noun filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniqueKey</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT##000100039X</td>\n",
       "      <td>[timeless,  gibran,  backs,  content,  means, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN##000100039X</td>\n",
       "      <td>[ prophet,  kahlil,  gibran,  thirty,  years, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3##000100039X</td>\n",
       "      <td>[ first,  books,  recall,  collection,  gibran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65##000100039X</td>\n",
       "      <td>[prophet,  kahlil,  work,  world,  million,  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV##000100039X</td>\n",
       "      <td>[gibran,  khalil,  gibran,  born,  one thousan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    uniqueKey  \\\n",
       "0  A2XQ5LZHTD4AFT##000100039X   \n",
       "1   AF7CSSGV93RXN##000100039X   \n",
       "2  A1NPNGWBVD9AK3##000100039X   \n",
       "3  A3IS4WGMFR4X65##000100039X   \n",
       "4   AWLFVCT9128JV##000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  [timeless,  gibran,  backs,  content,  means, ...  \n",
       "1  [ prophet,  kahlil,  gibran,  thirty,  years, ...  \n",
       "2  [ first,  books,  recall,  collection,  gibran...  \n",
       "3  [prophet,  kahlil,  work,  world,  million,  c...  \n",
       "4  [gibran,  khalil,  gibran,  born,  one thousan...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId        asin\n",
       "0  A2XQ5LZHTD4AFT  000100039X\n",
       "1   AF7CSSGV93RXN  000100039X\n",
       "2  A1NPNGWBVD9AK3  000100039X\n",
       "3  A3IS4WGMFR4X65  000100039X\n",
       "4   AWLFVCT9128JV  000100039X"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame(df0.uniqueKey.str.split('##',1).tolist(),columns = ['userId','asin'])\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[timeless,  gibran,  backs,  content,  means, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ prophet,  kahlil,  gibran,  thirty,  years, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ first,  books,  recall,  collection,  gibran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[prophet,  kahlil,  work,  world,  million,  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gibran,  khalil,  gibran,  born,  one thousan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText\n",
       "0  [timeless,  gibran,  backs,  content,  means, ...\n",
       "1  [ prophet,  kahlil,  gibran,  thirty,  years, ...\n",
       "2  [ first,  books,  recall,  collection,  gibran...\n",
       "3  [prophet,  kahlil,  work,  world,  million,  c...\n",
       "4  [gibran,  khalil,  gibran,  born,  one thousan..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviewText = pd.DataFrame(df0['reviewText'])\n",
    "df_reviewText.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[timeless,  gibran,  backs,  content,  means, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ prophet,  kahlil,  gibran,  thirty,  years, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ first,  books,  recall,  collection,  gibran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[prophet,  kahlil,  work,  world,  million,  c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[gibran,  khalil,  gibran,  born,  one thousan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId        asin  \\\n",
       "0  A2XQ5LZHTD4AFT  000100039X   \n",
       "1   AF7CSSGV93RXN  000100039X   \n",
       "2  A1NPNGWBVD9AK3  000100039X   \n",
       "3  A3IS4WGMFR4X65  000100039X   \n",
       "4   AWLFVCT9128JV  000100039X   \n",
       "\n",
       "                                          reviewText  \n",
       "0  [timeless,  gibran,  backs,  content,  means, ...  \n",
       "1  [ prophet,  kahlil,  gibran,  thirty,  years, ...  \n",
       "2  [ first,  books,  recall,  collection,  gibran...  \n",
       "3  [prophet,  kahlil,  work,  world,  million,  c...  \n",
       "4  [gibran,  khalil,  gibran,  born,  one thousan...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.concat([df1, df_reviewText], axis=1)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 582711/582711 [00:00<00:00, 1218345.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>wordCountBefore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A2XQ5LZHTD4AFT</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[timeless,  gibran,  backs,  content,  means, ...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AF7CSSGV93RXN</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ prophet,  kahlil,  gibran,  thirty,  years, ...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A1NPNGWBVD9AK3</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[ first,  books,  recall,  collection,  gibran...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A3IS4WGMFR4X65</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[prophet,  kahlil,  work,  world,  million,  c...</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AWLFVCT9128JV</td>\n",
       "      <td>000100039X</td>\n",
       "      <td>[gibran,  khalil,  gibran,  born,  one thousan...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           userId        asin  \\\n",
       "0  A2XQ5LZHTD4AFT  000100039X   \n",
       "1   AF7CSSGV93RXN  000100039X   \n",
       "2  A1NPNGWBVD9AK3  000100039X   \n",
       "3  A3IS4WGMFR4X65  000100039X   \n",
       "4   AWLFVCT9128JV  000100039X   \n",
       "\n",
       "                                          reviewText  wordCountBefore  \n",
       "0  [timeless,  gibran,  backs,  content,  means, ...               49  \n",
       "1  [ prophet,  kahlil,  gibran,  thirty,  years, ...               19  \n",
       "2  [ first,  books,  recall,  collection,  gibran...               76  \n",
       "3  [prophet,  kahlil,  work,  world,  million,  c...              142  \n",
       "4  [gibran,  khalil,  gibran,  born,  one thousan...               48  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_01 = df_new.assign(wordCountBefore = df_new['reviewText'].progress_apply(lambda review:len(review)))\n",
    "df_new_01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:: 100%|██████████| 47864/47864 [00:00<00:00, 1160869.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>frequency</th>\n",
       "      <th>normalised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>124420</td>\n",
       "      <td>culturebound</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124421</td>\n",
       "      <td>gilded</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>124422</td>\n",
       "      <td>adlibbing</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124423</td>\n",
       "      <td>autoread</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>124424</td>\n",
       "      <td>thenardier</td>\n",
       "      <td>8</td>\n",
       "      <td>0.016461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index          word  frequency  normalised\n",
       "0  124420  culturebound          8    0.016461\n",
       "1  124421        gilded          8    0.016461\n",
       "2  124422     adlibbing          8    0.016461\n",
       "3  124423      autoread          8    0.016461\n",
       "4  124424    thenardier          8    0.016461"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dic_df01['word'] = final_dic_df01['word'].progress_apply(lambda word: word.replace(\" \",\"\"))\n",
    "final_dic_df01 = final_dic_df01.reset_index()\n",
    "final_dic_df01.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'culturebound': 0,\n",
       " 'gilded': 1,\n",
       " 'adlibbing': 2,\n",
       " 'autoread': 3,\n",
       " 'thenardier': 4,\n",
       " 'schuhart': 5,\n",
       " 'swich': 6,\n",
       " 'allignment': 7,\n",
       " 'sullenbergers': 8,\n",
       " 'joyed': 9,\n",
       " 'loveatfirst': 10,\n",
       " 'bamiyan': 11,\n",
       " 'mft': 12,\n",
       " 'huh': 13,\n",
       " 'sandford': 14,\n",
       " 'nathansons': 15,\n",
       " 'sairas': 16,\n",
       " 'balduccis': 17,\n",
       " 'showpieces': 18,\n",
       " 'richesons': 19,\n",
       " 'kimelman': 20,\n",
       " 'mopup': 21,\n",
       " 'innis': 22,\n",
       " 'shimamoto': 23,\n",
       " 'yolande': 24,\n",
       " 'stewpot': 25,\n",
       " 'tristates': 26,\n",
       " 'halfbillion': 27,\n",
       " 'prejudicially': 28,\n",
       " 'trashbin': 29,\n",
       " 'bci': 30,\n",
       " 'virgie': 31,\n",
       " 'richeson': 32,\n",
       " 'ismaes': 33,\n",
       " 'massage': 34,\n",
       " 'andechs': 35,\n",
       " 'haberdashers': 36,\n",
       " 'wanta': 37,\n",
       " 'brickwork': 38,\n",
       " 'otherthe': 39,\n",
       " 'bf4': 40,\n",
       " 'birnes': 41,\n",
       " 'phosphates': 42,\n",
       " 'corners': 43,\n",
       " 'forsworn': 44,\n",
       " 'expertize': 45,\n",
       " 'asaph': 46,\n",
       " 'lky': 47,\n",
       " 'dorfmans': 48,\n",
       " 'ranes': 49,\n",
       " 'panarab': 50,\n",
       " 'bassackwards': 51,\n",
       " 'doubleminded': 52,\n",
       " 'milisant': 53,\n",
       " 'financialneeds': 54,\n",
       " 'doiron': 55,\n",
       " 'eyestones': 56,\n",
       " 'belov': 57,\n",
       " 'aleut': 58,\n",
       " 'lothrop': 59,\n",
       " 'warholic': 60,\n",
       " 'toolbelt': 61,\n",
       " 'judeokhazars': 62,\n",
       " 'baylorbates': 63,\n",
       " 'ecnomic': 64,\n",
       " 'lank': 65,\n",
       " 'spiritist': 66,\n",
       " 'smatrix': 67,\n",
       " 'ahlquists': 68,\n",
       " '1minute': 69,\n",
       " 'eversince': 70,\n",
       " 'consecrating': 71,\n",
       " 'manofwar': 72,\n",
       " 'troubadors': 73,\n",
       " 'k4': 74,\n",
       " 'orthdox': 75,\n",
       " 'sokrates': 76,\n",
       " 'celeste': 77,\n",
       " 'zubrys': 78,\n",
       " 'brands': 79,\n",
       " 'mishandle': 80,\n",
       " 'nuttings': 81,\n",
       " 'darkeness': 82,\n",
       " 'imdalind': 83,\n",
       " 'underneath': 84,\n",
       " 'colma': 85,\n",
       " 'preassassination': 86,\n",
       " 'itafter': 87,\n",
       " 'unavenged': 88,\n",
       " 'tenneys': 89,\n",
       " 'alianore': 90,\n",
       " 'patman': 91,\n",
       " 'bashing': 92,\n",
       " 'faten': 93,\n",
       " 'optimus': 94,\n",
       " 'starbase': 95,\n",
       " 'vtm': 96,\n",
       " 'brandbuilding': 97,\n",
       " 'concussive': 98,\n",
       " 'combatready': 99,\n",
       " 'malabo': 100,\n",
       " 'elvy': 101,\n",
       " 'jersualem': 102,\n",
       " 'impressionistically': 103,\n",
       " 'rendevouz': 104,\n",
       " 'witnessess': 105,\n",
       " 'penndutch': 106,\n",
       " 'gervaises': 107,\n",
       " 'knowin': 108,\n",
       " 'sobfest': 109,\n",
       " 'krenovs': 110,\n",
       " 'attactive': 111,\n",
       " 'kerkeling': 112,\n",
       " 'boisterously': 113,\n",
       " 'instrumentalist': 114,\n",
       " 'nyingma': 115,\n",
       " 'karilee': 116,\n",
       " 'wedgie': 117,\n",
       " 'tisch': 118,\n",
       " 'tyrannize': 119,\n",
       " 'heartful': 120,\n",
       " 'nearend': 121,\n",
       " 'thoughfully': 122,\n",
       " 'goldport': 123,\n",
       " 'immortalists': 124,\n",
       " 'vlad': 125,\n",
       " 'clickbank': 126,\n",
       " 'laguerta': 127,\n",
       " 'corsonknowles': 128,\n",
       " 'pretension': 129,\n",
       " 'monday': 130,\n",
       " 'tarman': 131,\n",
       " 'synthesist': 132,\n",
       " 'ageish': 133,\n",
       " 'aframe': 134,\n",
       " 'kochans': 135,\n",
       " 'underuse': 136,\n",
       " 'sorin': 137,\n",
       " 'dondo': 138,\n",
       " 'unreconcilable': 139,\n",
       " 'keiras': 140,\n",
       " 'headphone': 141,\n",
       " 'midshipmans': 142,\n",
       " 'viewand': 143,\n",
       " 'matrist': 144,\n",
       " 'starsis': 145,\n",
       " 'voy': 146,\n",
       " 'ponte': 147,\n",
       " 'neareast': 148,\n",
       " 'antelopes': 149,\n",
       " 'roseto': 150,\n",
       " 'marilees': 151,\n",
       " 'cenobites': 152,\n",
       " 'sergi': 153,\n",
       " 'patriarchies': 154,\n",
       " 'insteadthe': 155,\n",
       " 'greeters': 156,\n",
       " 'lathbury': 157,\n",
       " 'defectives': 158,\n",
       " 'rileysmith': 159,\n",
       " 'footstomping': 160,\n",
       " 'bamf': 161,\n",
       " 'glimpes': 162,\n",
       " 'exgays': 163,\n",
       " 'orders': 164,\n",
       " 'stumbler': 165,\n",
       " 'babits': 166,\n",
       " 'halfasleep': 167,\n",
       " 'farse': 168,\n",
       " 'boisterousness': 169,\n",
       " 'quarried': 170,\n",
       " 'liberazione': 171,\n",
       " 'delmonico': 172,\n",
       " 'notsobig': 173,\n",
       " 'firstrun': 174,\n",
       " 'eighty-ninethousand': 175,\n",
       " 'littleused': 176,\n",
       " 'ropework': 177,\n",
       " 'delectables': 178,\n",
       " 'afros': 179,\n",
       " 'norcourt': 180,\n",
       " 'nerudas': 181,\n",
       " 'midsomer': 182,\n",
       " 'nabbing': 183,\n",
       " 'warneham': 184,\n",
       " 'onehundredandtwothousandandeleven': 185,\n",
       " 'glossing': 186,\n",
       " 'mcswain': 187,\n",
       " 'quasireligion': 188,\n",
       " 'redblack': 189,\n",
       " 'leandra': 190,\n",
       " 'truett': 191,\n",
       " 'mourn': 192,\n",
       " 'fisheye': 193,\n",
       " 'intendeds': 194,\n",
       " 'luckman': 195,\n",
       " 'reher': 196,\n",
       " 'updike': 197,\n",
       " 'joris': 198,\n",
       " 'deanna': 199,\n",
       " 'niemeyers': 200,\n",
       " 'tanni': 201,\n",
       " 'pottinger': 202,\n",
       " 'lovebased': 203,\n",
       " 'minimystery': 204,\n",
       " 'uninstalling': 205,\n",
       " 'wil': 206,\n",
       " 'phychological': 207,\n",
       " 'ginko': 208,\n",
       " 'hermia': 209,\n",
       " 'peeped': 210,\n",
       " 'cannelloni': 211,\n",
       " 'quangha': 212,\n",
       " 'ipod': 213,\n",
       " 'bookdiscussion': 214,\n",
       " 'reciprocality': 215,\n",
       " 'poeticism': 216,\n",
       " 'prevalently': 217,\n",
       " 'cleaning': 218,\n",
       " 'bregg': 219,\n",
       " 'smallwoods': 220,\n",
       " 'hartwigs': 221,\n",
       " 'thoughtpatterns': 222,\n",
       " 'assing': 223,\n",
       " 'misson': 224,\n",
       " 'toolittle': 225,\n",
       " 'coreography': 226,\n",
       " 'pretwentieth': 227,\n",
       " 'muscley': 228,\n",
       " 'screaming': 229,\n",
       " 'architected': 230,\n",
       " 'homeland': 231,\n",
       " 'eckerson': 232,\n",
       " 'csk': 233,\n",
       " 'goodytwo': 234,\n",
       " 'quasidemons': 235,\n",
       " 'cybils': 236,\n",
       " 'zepplin': 237,\n",
       " 'pazlar': 238,\n",
       " 'pau': 239,\n",
       " 'dayfor': 240,\n",
       " 'wsi': 241,\n",
       " 'meuniere': 242,\n",
       " 'powerusers': 243,\n",
       " 'xdoclet': 244,\n",
       " 'cybercrime': 245,\n",
       " 'desirees': 246,\n",
       " 'recombined': 247,\n",
       " 'teoh': 248,\n",
       " 'capricorns': 249,\n",
       " 'weightings': 250,\n",
       " 'programers': 251,\n",
       " 'acls': 252,\n",
       " 'tbill': 253,\n",
       " 'information3': 254,\n",
       " 'increadible': 255,\n",
       " 'stickin': 256,\n",
       " 'saars': 257,\n",
       " 'vitriole': 258,\n",
       " 'gelding': 259,\n",
       " 'relationshipthe': 260,\n",
       " 'stole': 261,\n",
       " 'uncrossed': 262,\n",
       " 'upir': 263,\n",
       " 'applescripts': 264,\n",
       " 'scripter': 265,\n",
       " 'futs': 266,\n",
       " 'baud': 267,\n",
       " 'optimistic': 268,\n",
       " 'darknesses': 269,\n",
       " 'bacchanalia': 270,\n",
       " 'betide': 271,\n",
       " 'lactosefree': 272,\n",
       " 'misteps': 273,\n",
       " 'interfer': 274,\n",
       " 'scalars': 275,\n",
       " 'olio': 276,\n",
       " 'explanitory': 277,\n",
       " 'milennium': 278,\n",
       " 'franz': 279,\n",
       " 'granddads': 280,\n",
       " 'thiele': 281,\n",
       " 'corydon': 282,\n",
       " 'alligned': 283,\n",
       " 'hardput': 284,\n",
       " 'nondesigner': 285,\n",
       " 'arcane': 286,\n",
       " 'empanada': 287,\n",
       " 'itincluding': 288,\n",
       " 'vernius': 289,\n",
       " 'mchale': 290,\n",
       " 'valjeans': 291,\n",
       " 'brombergs': 292,\n",
       " 'concertina': 293,\n",
       " 'backhands': 294,\n",
       " 'prostrations': 295,\n",
       " 'hrd': 296,\n",
       " 'finishers': 297,\n",
       " 'forlornly': 298,\n",
       " 'knighton': 299,\n",
       " 'slavenka': 300,\n",
       " 'altmeyer': 301,\n",
       " 'glanville': 302,\n",
       " 'echoing': 303,\n",
       " 'stigmatic': 304,\n",
       " 'ussc': 305,\n",
       " 'narcistic': 306,\n",
       " 'snokes': 307,\n",
       " 'jauntily': 308,\n",
       " 'isought': 309,\n",
       " 'horrocks': 310,\n",
       " 'ssdi': 311,\n",
       " 'worldsthe': 312,\n",
       " 'landiss': 313,\n",
       " 'frieser': 314,\n",
       " 'austrohungarians': 315,\n",
       " 'istas': 316,\n",
       " 'taotao': 317,\n",
       " 'haddie': 318,\n",
       " 'instituitions': 319,\n",
       " 'dybbuk': 320,\n",
       " 'oversaturation': 321,\n",
       " 'priggishness': 322,\n",
       " 'badminton': 323,\n",
       " 'woolrichs': 324,\n",
       " 'unsucessfully': 325,\n",
       " 'p28': 326,\n",
       " 'nonparent': 327,\n",
       " 'nepotistic': 328,\n",
       " 'spitball': 329,\n",
       " 'intriques': 330,\n",
       " 'pagesreviewer': 331,\n",
       " 'ahah': 332,\n",
       " 'winds': 333,\n",
       " 'mgr': 334,\n",
       " 'perscribed': 335,\n",
       " 'crabmeat': 336,\n",
       " 'painstakenly': 337,\n",
       " 'refurbishment': 338,\n",
       " 'disassembly': 339,\n",
       " 'html': 340,\n",
       " 'luggage': 341,\n",
       " 'reconsiderations': 342,\n",
       " 'wellphotographed': 343,\n",
       " 'zylberberg': 344,\n",
       " 'crispier': 345,\n",
       " 'barrelling': 346,\n",
       " 'hilger': 347,\n",
       " 'ltyrosine': 348,\n",
       " 'junichiro': 349,\n",
       " 'starsone': 350,\n",
       " 'rosemont': 351,\n",
       " 'darwishs': 352,\n",
       " 'painchaudsteinman': 353,\n",
       " 'chaitins': 354,\n",
       " 'coproduced': 355,\n",
       " 'monkies': 356,\n",
       " 'recpies': 357,\n",
       " 'underbaked': 358,\n",
       " 'philp': 359,\n",
       " 'thraxton': 360,\n",
       " 'optimality': 361,\n",
       " 'lmbs': 362,\n",
       " 'mosts': 363,\n",
       " 'idg': 364,\n",
       " 'briefness': 365,\n",
       " 'chocolatedipped': 366,\n",
       " 'hickle': 367,\n",
       " 'ultra': 368,\n",
       " 'laserguided': 369,\n",
       " 'kriyas': 370,\n",
       " 'brodo': 371,\n",
       " 'muchused': 372,\n",
       " 'spokenword': 373,\n",
       " 'pomerol': 374,\n",
       " 'penn': 375,\n",
       " 'adelard': 376,\n",
       " 'welcomed': 377,\n",
       " 'handson': 378,\n",
       " 'molotovs': 379,\n",
       " 'unestablished': 380,\n",
       " 'knolls': 381,\n",
       " 'pilleys': 382,\n",
       " '5x5': 383,\n",
       " 'nonoriginal': 384,\n",
       " 'brightons': 385,\n",
       " 'monopoles': 386,\n",
       " 'doormans': 387,\n",
       " 'particpants': 388,\n",
       " 'paribus': 389,\n",
       " 'pivotal': 390,\n",
       " 'injury': 391,\n",
       " 'twothousandandthirty-three': 392,\n",
       " 'murderforhire': 393,\n",
       " 'milly': 394,\n",
       " 'humus': 395,\n",
       " 'topicsthe': 396,\n",
       " 'aysgarth': 397,\n",
       " 'condimenti': 398,\n",
       " 'imprecisely': 399,\n",
       " 'mafouz': 400,\n",
       " 'pittmans': 401,\n",
       " '3months': 402,\n",
       " 'laught': 403,\n",
       " 'sportsrelated': 404,\n",
       " 'groundsense': 405,\n",
       " 'clarisses': 406,\n",
       " 'reabsorbed': 407,\n",
       " 'seminomadic': 408,\n",
       " 'tocks': 409,\n",
       " 'recommnend': 410,\n",
       " 'atholl': 411,\n",
       " 'wirz': 412,\n",
       " 'swell': 413,\n",
       " 'bookher': 414,\n",
       " 'scrawls': 415,\n",
       " 'stemware': 416,\n",
       " 'iapps': 417,\n",
       " 'gravitydefying': 418,\n",
       " 'blackberrys': 419,\n",
       " 'facepalming': 420,\n",
       " '1000year': 421,\n",
       " 'harfleur': 422,\n",
       " 'bantry': 423,\n",
       " 'architypes': 424,\n",
       " 'azincourt': 425,\n",
       " 'portlands': 426,\n",
       " 'cafo': 427,\n",
       " 'themsevles': 428,\n",
       " 'hadels': 429,\n",
       " 'proportioning': 430,\n",
       " 'kyrgyz': 431,\n",
       " 'adolfs': 432,\n",
       " 'overaged': 433,\n",
       " 'bennewitz': 434,\n",
       " 'applies': 435,\n",
       " 'thou': 436,\n",
       " 'zamiatins': 437,\n",
       " 'cmc': 438,\n",
       " 'underpromise': 439,\n",
       " 'switzerlands': 440,\n",
       " 'sants': 441,\n",
       " 'bustillos': 442,\n",
       " 'goodish': 443,\n",
       " 'ufs': 444,\n",
       " 'reenvisioned': 445,\n",
       " 'themall': 446,\n",
       " 'cocainesnorting': 447,\n",
       " 'tannahill': 448,\n",
       " 'util': 449,\n",
       " 'shuttering': 450,\n",
       " 'slovaks': 451,\n",
       " 'saucemaking': 452,\n",
       " 'seeley': 453,\n",
       " 'prevelance': 454,\n",
       " 'bacheliers': 455,\n",
       " 'diddled': 456,\n",
       " 'stephan': 457,\n",
       " 'antidepressents': 458,\n",
       " 'rutan': 459,\n",
       " 'katrins': 460,\n",
       " 'insisted': 461,\n",
       " 'kimmy': 462,\n",
       " 'ups': 463,\n",
       " 'distracters': 464,\n",
       " 'pillowy': 465,\n",
       " 'shor': 466,\n",
       " 'tenderfoot': 467,\n",
       " 'sixpoint': 468,\n",
       " 'ryzaard': 469,\n",
       " 'neoclassicism': 470,\n",
       " 'striders': 471,\n",
       " 'baulk': 472,\n",
       " 'thisandthat': 473,\n",
       " 'nontestable': 474,\n",
       " 'rohl': 475,\n",
       " 'duboses': 476,\n",
       " 'changeby': 477,\n",
       " 'galanors': 478,\n",
       " 'bongos': 479,\n",
       " 'softshell': 480,\n",
       " 'serghetti': 481,\n",
       " 'jefferss': 482,\n",
       " 'benumbed': 483,\n",
       " 'theologiae': 484,\n",
       " 'esteemed': 485,\n",
       " 'marincola': 486,\n",
       " 'anodos': 487,\n",
       " 'cyberthriller': 488,\n",
       " 'bagoass': 489,\n",
       " 'shockproof': 490,\n",
       " 'learnin': 491,\n",
       " 'palistinians': 492,\n",
       " 'exoskeletons': 493,\n",
       " 'rashel': 494,\n",
       " 'nickis': 495,\n",
       " 'wordsi': 496,\n",
       " 'vorres': 497,\n",
       " 'clayer': 498,\n",
       " 'schizophrenically': 499,\n",
       " 'poona': 500,\n",
       " 'gloominess': 501,\n",
       " 'guilters': 502,\n",
       " 'okadas': 503,\n",
       " 'contraditions': 504,\n",
       " 'aculo': 505,\n",
       " 'otb': 506,\n",
       " 'longgrain': 507,\n",
       " 'sentinor': 508,\n",
       " 'ploughshares': 509,\n",
       " 'stagecoaches': 510,\n",
       " 'strasslers': 511,\n",
       " 'weta': 512,\n",
       " 'drollness': 513,\n",
       " 'energyskeptic': 514,\n",
       " 'toothsome': 515,\n",
       " 'silpat': 516,\n",
       " 'ideally': 517,\n",
       " 'nutmegs': 518,\n",
       " 'sovreign': 519,\n",
       " 'makefiles': 520,\n",
       " 'transcendentally': 521,\n",
       " 'salks': 522,\n",
       " 'chestertons': 523,\n",
       " 'hetton': 524,\n",
       " '2t': 525,\n",
       " 'malkuth': 526,\n",
       " 'shuffler': 527,\n",
       " 'europeanbased': 528,\n",
       " 'craftiest': 529,\n",
       " 'swett': 530,\n",
       " 'selfevaluations': 531,\n",
       " 'zweibel': 532,\n",
       " 'kee': 533,\n",
       " 'videodrome': 534,\n",
       " 'churchwells': 535,\n",
       " 'aileana': 536,\n",
       " 'thingie': 537,\n",
       " 'esoterics': 538,\n",
       " 'jugurthine': 539,\n",
       " 'cappucino': 540,\n",
       " 'eocene': 541,\n",
       " 'kelis': 542,\n",
       " 'picures': 543,\n",
       " 'tcbs': 544,\n",
       " 'laotians': 545,\n",
       " 'weightrelated': 546,\n",
       " 'ponzis': 547,\n",
       " 'brumfields': 548,\n",
       " 'wellrooted': 549,\n",
       " 'lohr': 550,\n",
       " 'or3': 551,\n",
       " 'parametric': 552,\n",
       " 'leghorn': 553,\n",
       " '20foot': 554,\n",
       " 'undogmatic': 555,\n",
       " 'beggers': 556,\n",
       " 'foregrounds': 557,\n",
       " 'indi': 558,\n",
       " 'spiritthe': 559,\n",
       " 'overwrought': 560,\n",
       " 'pineault': 561,\n",
       " 'ginger': 562,\n",
       " 'whimsical': 563,\n",
       " 'secondlargest': 564,\n",
       " 'fathermothergod': 565,\n",
       " 'aready': 566,\n",
       " 'lilylivered': 567,\n",
       " 'lightthe': 568,\n",
       " 'joyboy': 569,\n",
       " 'hohman': 570,\n",
       " 'cookbookand': 571,\n",
       " 'sforzas': 572,\n",
       " 'semiexperienced': 573,\n",
       " 'dispensationalisms': 574,\n",
       " 'bounteous': 575,\n",
       " 'wheelbarrows': 576,\n",
       " 'sweetness': 577,\n",
       " 'schulberg': 578,\n",
       " 'baldabiou': 579,\n",
       " 'harwell': 580,\n",
       " 'sunroom': 581,\n",
       " 'whitesonly': 582,\n",
       " 'scanted': 583,\n",
       " 'kbg': 584,\n",
       " 'hemlines': 585,\n",
       " 'predestiny': 586,\n",
       " 'stonehouse': 587,\n",
       " 'historyits': 588,\n",
       " 'dawnthief': 589,\n",
       " 'jibber': 590,\n",
       " 'macandrew': 591,\n",
       " 'spirtually': 592,\n",
       " 'culvert': 593,\n",
       " 'subrosa': 594,\n",
       " 'chandler': 595,\n",
       " 'havesome': 596,\n",
       " 'fekkais': 597,\n",
       " 'catalonian': 598,\n",
       " 'clunky': 599,\n",
       " 'florys': 600,\n",
       " 'vietnames': 601,\n",
       " 'pachyderm': 602,\n",
       " 'excavator': 603,\n",
       " 'agi': 604,\n",
       " 'effeciency': 605,\n",
       " 'sandes': 606,\n",
       " 'mediumistic': 607,\n",
       " 'postbook': 608,\n",
       " 'wakeupcall': 609,\n",
       " 'genetically': 610,\n",
       " 'flycatchers': 611,\n",
       " 'strongs': 612,\n",
       " 'requirementschapter': 613,\n",
       " 'steinfeld': 614,\n",
       " 'debruce': 615,\n",
       " 'boobytraps': 616,\n",
       " 'cached': 617,\n",
       " 'epiny': 618,\n",
       " 'biophysicist': 619,\n",
       " 'spectroscopy': 620,\n",
       " 'celtica': 621,\n",
       " 'bettersuited': 622,\n",
       " 'haruki': 623,\n",
       " 'culhane': 624,\n",
       " 'matching': 625,\n",
       " 'itsiks': 626,\n",
       " '6step': 627,\n",
       " 'prospective': 628,\n",
       " 'introductionchapter': 629,\n",
       " 'okavango': 630,\n",
       " 'tablebased': 631,\n",
       " 'nofluff': 632,\n",
       " 'dependancy': 633,\n",
       " 'useability': 634,\n",
       " 'gillingham': 635,\n",
       " 'soyfoods': 636,\n",
       " 'holidaying': 637,\n",
       " 'historicallyaccurate': 638,\n",
       " 'talkes': 639,\n",
       " 'portico': 640,\n",
       " 'hadassahs': 641,\n",
       " 'appelfeld': 642,\n",
       " 'twocar': 643,\n",
       " 'philidor': 644,\n",
       " 'campaign': 645,\n",
       " 'floreys': 646,\n",
       " 'antipater': 647,\n",
       " 'physican': 648,\n",
       " 'semirelated': 649,\n",
       " 'treatsie': 650,\n",
       " 'etiolated': 651,\n",
       " 'selfrevelations': 652,\n",
       " 'godness': 653,\n",
       " 'tard': 654,\n",
       " 'bushthe': 655,\n",
       " 'pigou': 656,\n",
       " 'perserveres': 657,\n",
       " 'incinerator': 658,\n",
       " 'fasttwitch': 659,\n",
       " 'nonavian': 660,\n",
       " 'insurrectionists': 661,\n",
       " 'heror': 662,\n",
       " 'tradepaperback': 663,\n",
       " 'mtn': 664,\n",
       " 'adultonset': 665,\n",
       " 'bacchanalian': 666,\n",
       " 'rintys': 667,\n",
       " 'ehs': 668,\n",
       " 'mannies': 669,\n",
       " 'bellatrix': 670,\n",
       " 'orton': 671,\n",
       " '10monthold': 672,\n",
       " 'atheology': 673,\n",
       " 'annett': 674,\n",
       " 'langenscheidts': 675,\n",
       " 'tibon': 676,\n",
       " 'platos': 677,\n",
       " 'diasporic': 678,\n",
       " 'suport': 679,\n",
       " 'sisto': 680,\n",
       " 'mkdir': 681,\n",
       " 'tajiks': 682,\n",
       " 'chauffeuring': 683,\n",
       " 'virtuosos': 684,\n",
       " 'scrumble': 685,\n",
       " 'darning': 686,\n",
       " 'willaim': 687,\n",
       " 'tenhuis': 688,\n",
       " 'prekatrina': 689,\n",
       " 'biblethumper': 690,\n",
       " 'wyldes': 691,\n",
       " 'quita': 692,\n",
       " 'deneen': 693,\n",
       " 'bkf': 694,\n",
       " 'doughtys': 695,\n",
       " 'castagno': 696,\n",
       " 'twothousandandfifty-seven': 697,\n",
       " 'mattos': 698,\n",
       " 'allstrong': 699,\n",
       " 'candlewick': 700,\n",
       " 'semidetached': 701,\n",
       " 'untrammelled': 702,\n",
       " 'sweeting': 703,\n",
       " 'floppies': 704,\n",
       " 'illichs': 705,\n",
       " 'modernday': 706,\n",
       " 'tongueincheek': 707,\n",
       " 'daoine': 708,\n",
       " 'thirdgraders': 709,\n",
       " 'printmaking': 710,\n",
       " 'ramez': 711,\n",
       " 'fiveinch': 712,\n",
       " 'kristalnacht': 713,\n",
       " 'reconciled': 714,\n",
       " 'malum': 715,\n",
       " 'simbel': 716,\n",
       " 'baboo': 717,\n",
       " 'propertys': 718,\n",
       " 'serenades': 719,\n",
       " 'serang': 720,\n",
       " 'relinquish': 721,\n",
       " 'neels': 722,\n",
       " 'saxophonist': 723,\n",
       " 'sutherlin': 724,\n",
       " 'incompletion': 725,\n",
       " 'rickshaws': 726,\n",
       " 'tastewise': 727,\n",
       " 'slingshots': 728,\n",
       " 'ealing': 729,\n",
       " 'mongoloids': 730,\n",
       " 'highseas': 731,\n",
       " 'polhemus': 732,\n",
       " 'insourcing': 733,\n",
       " 'actionpaced': 734,\n",
       " 'exchanged': 735,\n",
       " 'cambor': 736,\n",
       " 'orsoff': 737,\n",
       " 'mandels': 738,\n",
       " 'reiter': 739,\n",
       " 'mildreviewed': 740,\n",
       " 'opar': 741,\n",
       " 'smallformat': 742,\n",
       " 'earache': 743,\n",
       " 'ohmsfords': 744,\n",
       " 'zapatistas': 745,\n",
       " 'exup': 746,\n",
       " 'beauregards': 747,\n",
       " 'interlanders': 748,\n",
       " 'loooking': 749,\n",
       " '157th': 750,\n",
       " 'alfs': 751,\n",
       " 'functionless': 752,\n",
       " 'breakwater': 753,\n",
       " 'banco': 754,\n",
       " 'squeamish': 755,\n",
       " 'toooooo': 756,\n",
       " 'tomatobasil': 757,\n",
       " 'viscosity': 758,\n",
       " 'maharshis': 759,\n",
       " 'rewinds': 760,\n",
       " 'sebs': 761,\n",
       " 'attendent': 762,\n",
       " 'avians': 763,\n",
       " 'selfdeterminism': 764,\n",
       " '8yrs': 765,\n",
       " 'ovenden': 766,\n",
       " 'renaldo': 767,\n",
       " 'busies': 768,\n",
       " 'playwrites': 769,\n",
       " 'slyness': 770,\n",
       " 'golitsyns': 771,\n",
       " 'lascar': 772,\n",
       " 'tarns': 773,\n",
       " 'lacquerware': 774,\n",
       " 'shunting': 775,\n",
       " 'tunzelmann': 776,\n",
       " 'senseof': 777,\n",
       " 'rototilling': 778,\n",
       " 'prasad': 779,\n",
       " 'insurances': 780,\n",
       " 'rumkowskis': 781,\n",
       " 'responds': 782,\n",
       " 'read2': 783,\n",
       " 'germanstyle': 784,\n",
       " 'gueneveres': 785,\n",
       " 'twothousandandforty-nine': 786,\n",
       " 'wenlin': 787,\n",
       " 'deak': 788,\n",
       " 'generalplan': 789,\n",
       " 'arrangement': 790,\n",
       " 'vestibular': 791,\n",
       " 'reenvisioning': 792,\n",
       " 'noticible': 793,\n",
       " 'pidgins': 794,\n",
       " 'beautifuland': 795,\n",
       " 'mallowan': 796,\n",
       " 'protolanguages': 797,\n",
       " 'walks': 798,\n",
       " 'beaune': 799,\n",
       " 'intimidatingly': 800,\n",
       " 'mccreights': 801,\n",
       " 'dahlquists': 802,\n",
       " 'schwerpunkt': 803,\n",
       " 'mcwhorter': 804,\n",
       " 'koro': 805,\n",
       " 'sciencefictiony': 806,\n",
       " 'spellbind': 807,\n",
       " 'tarter': 808,\n",
       " 'sindbad': 809,\n",
       " 'christianas': 810,\n",
       " 'whispers': 811,\n",
       " 'bidden': 812,\n",
       " 'jaydens': 813,\n",
       " 'strawson': 814,\n",
       " 'georgy': 815,\n",
       " 'tens': 816,\n",
       " 'jauhars': 817,\n",
       " 'lamaar': 818,\n",
       " 'needlecrafters': 819,\n",
       " 'castels': 820,\n",
       " 'howand': 821,\n",
       " 'sashing': 822,\n",
       " 'postclassical': 823,\n",
       " 'sniped': 824,\n",
       " 'bumped': 825,\n",
       " 'inaguration': 826,\n",
       " 'perceptivity': 827,\n",
       " 'tati': 828,\n",
       " 'blowback': 829,\n",
       " 'cormia': 830,\n",
       " 'latetalking': 831,\n",
       " 'borghese': 832,\n",
       " 'rolan': 833,\n",
       " 'toecurlingly': 834,\n",
       " 'runts': 835,\n",
       " 'morcks': 836,\n",
       " 'vistors': 837,\n",
       " 'refound': 838,\n",
       " 'roschmann': 839,\n",
       " 'hilbergs': 840,\n",
       " 'fuschia': 841,\n",
       " 'earbuds': 842,\n",
       " 'clowney': 843,\n",
       " 'cutesiness': 844,\n",
       " 'heimbichners': 845,\n",
       " 'p8': 846,\n",
       " 'ladaisy': 847,\n",
       " 'ventriloquists': 848,\n",
       " 'prankish': 849,\n",
       " 'jou': 850,\n",
       " 'oflaherty': 851,\n",
       " 'dimiter': 852,\n",
       " 'harvill': 853,\n",
       " 'seahorses': 854,\n",
       " 'meadowmount': 855,\n",
       " 'crinkly': 856,\n",
       " 'farkas': 857,\n",
       " 'disinvited': 858,\n",
       " 'dreamingfor': 859,\n",
       " 'intitially': 860,\n",
       " 'wanderly': 861,\n",
       " 'ontheshelf': 862,\n",
       " 'salusa': 863,\n",
       " 'darkcolored': 864,\n",
       " 'foodbased': 865,\n",
       " 'iblis': 866,\n",
       " 'lawkeeping': 867,\n",
       " '40somethings': 868,\n",
       " 'styler': 869,\n",
       " 'spartak': 870,\n",
       " 'mihailovich': 871,\n",
       " 'florette': 872,\n",
       " 'intoxications': 873,\n",
       " 'inconsolably': 874,\n",
       " 'jeopardize': 875,\n",
       " 'phineass': 876,\n",
       " 'rattlers': 877,\n",
       " 'prerequisite': 878,\n",
       " 'saghred': 879,\n",
       " 'cheval': 880,\n",
       " 'twohundredandforty-ninethousand': 881,\n",
       " 'zaren': 882,\n",
       " 'condensed': 883,\n",
       " 'hankerin': 884,\n",
       " 'hegira': 885,\n",
       " 'heap': 886,\n",
       " 'warbling': 887,\n",
       " 'ixians': 888,\n",
       " 'darya': 889,\n",
       " 'krauses': 890,\n",
       " 'vronskys': 891,\n",
       " 'gulden': 892,\n",
       " 'coowners': 893,\n",
       " 'eruptive': 894,\n",
       " 'nimbleness': 895,\n",
       " 'episteme': 896,\n",
       " 'readig': 897,\n",
       " 'tosay': 898,\n",
       " 'knowit': 899,\n",
       " 'incurable': 900,\n",
       " 'readespecially': 901,\n",
       " 'hungerford': 902,\n",
       " 'bhairav': 903,\n",
       " 'puris': 904,\n",
       " 'poto': 905,\n",
       " 'selfdeliverance': 906,\n",
       " 'oversimple': 907,\n",
       " 'nomind': 908,\n",
       " 'arthropod': 909,\n",
       " 'superthin': 910,\n",
       " 'partmemoir': 911,\n",
       " 'princesse': 912,\n",
       " 'spellsinger': 913,\n",
       " 'mylas': 914,\n",
       " 'lant': 915,\n",
       " 'ards': 916,\n",
       " 'rememberer': 917,\n",
       " 'misguidance': 918,\n",
       " 'cpd': 919,\n",
       " 'gumby': 920,\n",
       " 'glossop': 921,\n",
       " 'contray': 922,\n",
       " 'welldifferentiated': 923,\n",
       " 'blacklists': 924,\n",
       " 'linnette': 925,\n",
       " 'selflimitation': 926,\n",
       " 'you3': 927,\n",
       " 'critizing': 928,\n",
       " 'worldwalking': 929,\n",
       " 'tenthgrade': 930,\n",
       " 'mangia': 931,\n",
       " 'wygant': 932,\n",
       " 'thys': 933,\n",
       " 'kubler': 934,\n",
       " 'apportion': 935,\n",
       " 'homeis': 936,\n",
       " 'tema': 937,\n",
       " 'stice': 938,\n",
       " 'paradisiacal': 939,\n",
       " 'westthe': 940,\n",
       " 'roesdahl': 941,\n",
       " 'wellwoods': 942,\n",
       " 'molinari': 943,\n",
       " 'mostpart': 944,\n",
       " 'supersystem': 945,\n",
       " 'traduced': 946,\n",
       " 'tenthcentury': 947,\n",
       " 'atkins': 948,\n",
       " 'lumpish': 949,\n",
       " 'anglesey': 950,\n",
       " 'concerened': 951,\n",
       " 'toin': 952,\n",
       " 'noshing': 953,\n",
       " 'alomas': 954,\n",
       " 'hellenization': 955,\n",
       " 'kareen': 956,\n",
       " 'nivel': 957,\n",
       " 'breadwinning': 958,\n",
       " 'post1980': 959,\n",
       " 'pique': 960,\n",
       " 'founts': 961,\n",
       " 'hopkinsville': 962,\n",
       " 'resurging': 963,\n",
       " 'upmanship': 964,\n",
       " 'synthesises': 965,\n",
       " 'arikara': 966,\n",
       " 'extirpation': 967,\n",
       " 'mazen': 968,\n",
       " 'lisicks': 969,\n",
       " 'libeling': 970,\n",
       " 'gogolov': 971,\n",
       " 'heedlessness': 972,\n",
       " 'reverenced': 973,\n",
       " 'merkaba': 974,\n",
       " 'anteater': 975,\n",
       " 'hellstorm': 976,\n",
       " 'arlena': 977,\n",
       " 'adultreviewed': 978,\n",
       " 'peopleto': 979,\n",
       " 'abbi': 980,\n",
       " 'whatd': 981,\n",
       " 'lifelessly': 982,\n",
       " 'nutured': 983,\n",
       " 'luella': 984,\n",
       " 'beliefsystems': 985,\n",
       " 'seeminglyendless': 986,\n",
       " 'cassidy': 987,\n",
       " 'furth': 988,\n",
       " 'ideosyncracies': 989,\n",
       " 'angevins': 990,\n",
       " 'soulish': 991,\n",
       " 'toths': 992,\n",
       " 'huneven': 993,\n",
       " 'remarriages': 994,\n",
       " 'devistated': 995,\n",
       " 'gilliams': 996,\n",
       " 'worldone': 997,\n",
       " 'antipolish': 998,\n",
       " 'haider': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_dict = final_dic_df01['word'].to_dict()\n",
    "inv_filtered_dict = {v: k for k, v in filtered_dict.items()}\n",
    "inv_filtered_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(review):\n",
    "    new_review = []\n",
    "    for word in review:\n",
    "        word = word.strip()\n",
    "        if word in inv_filtered_dict:\n",
    "            new_review.append(word)\n",
    "    return new_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  87%|████████▋ | 506106/582711 [00:09<00:01, 60786.18it/s]"
     ]
    }
   ],
   "source": [
    "df_new_02 = df_new_01.assign(filteredText = df_new_01['reviewText'].progress_apply(lambda review:filter_words(review)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_03 = df_new_02.assign(wordCountAfter = df_new_02['filteredText'].progress_apply(lambda review:len(review)))\n",
    "df_new_03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = 1 - df_new_03['wordCountAfter'].sum() / df_new_03['wordCountBefore'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average noun reduction achieved:\" + str(remaining*100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Association Rules Mining Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_books_bigReviews = pd.DataFrame(df_new_03[['asin','filteredText']].groupby(['asin'])['filteredText'].progress_apply(list))\n",
    "df_books_bigReviews = df_books_bigReviews.reset_index()\n",
    "df_books_bigReviews = df_books_bigReviews.assign(transactions = df_books_bigReviews['filteredText'].progress_apply(lambda reviews_lis:len(reviews_lis)))\n",
    "df_books_bigReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "\n",
    "# Support\n",
    "# Support is an indication of how frequently the itemset appears in the dataset.\n",
    "# Confidence\n",
    "# Confidence is an indication of how often the rule has been found to be true.\n",
    "# Lift\n",
    "# The ratio of the observed support to that expected if X and Y were independent.\n",
    "def apply_arm(transactions):\n",
    "    return list(apriori(transactions, min_support = 1/len(transactions), min_confidence = 1, min_lift = len(transactions), max_length = 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_with_arm = df_books_bigReviews[0:1000].assign(arm = df_books_bigReviews['filteredText'][0:1000].progress_apply(lambda list_of_reviews:apply_arm(list_of_reviews)))\n",
    "books_with_arm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_important_nouns(results):\n",
    "\n",
    "    imp_nns = []\n",
    "    for result in results:\n",
    "        if len(list(result)) > 3:\n",
    "            imp_nns = imp_nns + list(list(result))\n",
    "    return imp_nns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_nns_df = books_with_arm.assign(imp_nns = books_with_arm['arm'].progress_apply(lambda arms:get_important_nouns(list(pd.DataFrame(arms)['items']))))\n",
    "imp_nns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_nns_df = imp_nns_df[['asin','imp_nns']]\n",
    "imp_nns_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_nns_df.to_pickle(\"../data/interim/005_important_nouns.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# END OF FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
